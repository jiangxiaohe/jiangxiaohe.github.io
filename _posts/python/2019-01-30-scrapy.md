---
layout: post
title: python爬虫框架-scrapy
tags:
- 爬虫
categories: python
description: scrapy爬虫框架学习笔记
---

srapy库是一个快速功能强大的网络爬虫框架

安装`pip install scrapy`

在命令行测试`scrapy -h`

# Scrapy爬虫框架结构基础知识
框架是实现爬虫功能的一个软件结构和功能组件集合。爬虫框架是一个半成品，能够帮助用户实现专业网络爬虫。

<img src="{{ site.baseurl }}/resource/scrapy.jpg">

Engine
* 控制所有模块之间的数据流
* 根据条件触发事件
* 不需要用户修改

Downloader
* 根据请求下载网页
* 不需要用户修改

Scheduler
* 对所有爬取请求进行调度管理
* 不需要用户修改

Downloader Middleware
* 目的：实施Engine、Scheduler、Downloader之间进行用户可配置的控制
* 功能：修改、丢弃、新增请求或相应
* 用户可以编写配置代码

Spider
* 解析Downloader返回的相应(resource)
* 产生爬取项(scraped item)
* 产生额外的爬取请求(request)
* 需要用户编写配置代码

Item Pipelines
* 以流水线方式处理Spider产生的爬取项
* 由一组操作顺序组成，类似流水线，每个操作是一个Item Pipeline类型
* 可能操作包括：清理、检验、查重爬取项中的HTML数据、将数据存储到数据库
* 需要用户编写配置代码

Spider Middleware
* 目的：对请求和爬取项的再处理
* 功能：修改、丢弃、新增请求或爬取项
* 用户可以编写配置代码

# requests VS. scrapy
相同点：
* 都可以进行页面请求和爬取，python爬虫的两个重要技术路线
* 两者可用性都很好，文档丰富，入门简单
* 两者都没有处理js、提交表单、应对验证码等功能（可扩展）

不同点：

|requests|Scrapy|
|-|-|
|页面级爬虫              |网站级爬虫|
|功能库                  |框架|
|并发性考虑不足，性能较差  |并发性好，性能较好|
|重点在于页面下载         |重点在于爬虫结构|
|定制灵活                |一般定制灵活，深度定制困难
|上手十分简单             |入门稍难|

* 非常小的需求时，用requests库即可
* 不太小的需求，用scrapy库
* 定制程度高的需求（不考虑规模），自搭框架，requests>Scrapy

# Scrapy爬虫常用命令
Scrapy是为持续运行设计的专业爬虫框架，提供操作的Scrapy命令行。
Win下，启动cmd控制台。

命令格式：`>scrapy <command> [options] [args]`

|命令         |说明               |格式|
|-|-|-|
|startproject |创建一个新工程      |scrapy startproject <name> [dir]|
|genspider    |创建一个爬虫        |scrapy genspider [options] <name> <domain>|
|settings     |获得爬虫配置信息    |scrapy settings [options]|
|crawl        |运行一个爬虫        |scrapy crawl <spider>|
|list         |列出工程中所有爬虫  |scrapy list|
|shell        |启动URL调试命令行   |scrapy shell [url]|


# scrapy爬虫实例：获取HTML内容

# `yield`关键字和生成器

# Scrapy爬虫的数据类型

# scrapy爬虫实例：获取股票信息
