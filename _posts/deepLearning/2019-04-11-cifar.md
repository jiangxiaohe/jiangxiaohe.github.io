---
layout: post
title: CIFAR数据集实验
tags:
categories: deepLearning
description: 经典数据集
---

# CIFAR数据集

CIFAR-10数据集由10个类中的60000个32x32彩色图像组成，每个类有6000个图像。有50000个训练图像和10000个测试图像。 每个图像都标有10个类别中的一个（例如“飞机，汽车，鸟等”）。这些60,000个图像被划分为50,000个图像的训练集和10,000个图像的测试集。

* data_batch_1-5为五个训练集，test_batch为测试集
* 每个batch通过`unpickle`函数得到data和lable变量即可开始训练
* batches.meta包含一个python字典对象，内容有一个包含10个元素的列表

在[官网](http://www.cs.toronto.edu/~kriz/cifar.html)下载并按照说明进行数据预处理如下：

```python
import cv2
import numpy as np
def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict

# 数据预处理
#每一个batch包括10000张照片
dict=unpickle("data_batch_1")

batch_label=dict[b'batch_label']#长度是21，含义不明
#0-9范围内的10000个数字列表。索引i处的数字表示阵列数据中第i个图像的标签。
labels=dict[b'labels']
#共10000个元素，类型是numpy.ndarray，长度是3072，即32*32*3
#前1024个条目包含红色通道值，下一个1024表示绿色，最后1024个表示蓝色
#图像以行主顺序存储，因此数组的前32个条目是图像第一行的红色通道值。
data=dict[b'data']
filenames=dict[b'filenames']

#
batches=unpickle("D://nys//cifar-10-batches-py//batches.meta")
num_cases_per_batch=batches[b'num_cases_per_batch']
label_names=batches[b'label_names']
num_vis=batches[b'num_vis']
```

# keras程序

```python
from keras.datasets import mnist
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.models import Sequential
from keras.utils import np_utils
from keras.optimizers import RMSprop


(X_train, y_train), (X_test, y_test) = mnist.load_data()
# 首次使用会下载，可能出现网络问题，要自己下载mnist.npz，然后放在user\nys\.keras\datasets目录下

# data pre-processing
X_train = X_train.reshape(X_train.shape[0], -1) / 255.   # normalize
X_test = X_test.reshape(X_test.shape[0], -1) / 255.      # normalize
y_train = np_utils.to_categorical(y_train, num_classes=10) # 将单个标记转化为向量
y_test = np_utils.to_categorical(y_test, num_classes=10)

# 建立模型
model = Sequential([
        Dense(32,input_dim=784),
        Activation('relu'),
        Dense(10),
        Activation('softmax'),
        ])

# 选择优化器
rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)

# 激活模型
model.compile(optimizer=rmsprop,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 训练
print('Training ------------')
model.fit(X_train,y_train,nb_epoch=2,batch_size=32)# 每次训练32个数据

# 测试
print('\nTesting ------------')
# Evaluate the model with the metrics we defined earlier
loss, accuracy = model.evaluate(X_test, y_test)

print('test loss: ', loss)
print('test accuracy: ', accuracy)
```









000
