---
layout: post
title: 吴恩达1：神经网络和深度学习
tags:
categories: deepLearning
description: 课程笔记
---

5门课程一共16周的课程，完成课后作业，并且整理笔记。

这是一个相对完整的课程体系，比自己随便找资料效率更高。**coursera的课程费用需要每月$49，但是真正的成本是你的时间和精力！而且付费还能给你一定的监督，没必要省这点钱。**

作业和视频至少一样重要！

[网易云课程视频](https://mooc.study.163.com/smartSpec/detail/1001319001.htm)

参考前辈笔记：
* 主要参考[黄海广（包含全部的字幕）](http://www.ai-start.com/dl2017/)
* 主要参考[大树先生笔记](https://zhuanlan.zhihu.com/p/35333489)
* [!KyonHuang](http://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/)
* [红色石头](https://zhuanlan.zhihu.com/p/36453627)
* [毛帅](http://imshuai.com/tag/deeplearning-ai-notes/)


参考作业答案
* 主要参考[JudasDie/deeplearning.ai](https://github.com/JudasDie/deeplearning.ai)
* 主要参考[大树先生作业](https://blog.csdn.net/Koala_Tree/article/category/7186915)
* [enggen/Deep-Learning-Coursera](https://github.com/enggen/Deep-Learning-Coursera)
* [bighuang624](https://github.com/bighuang624/Andrew-Ng-Deep-Learning-notes/tree/master/assignments)

推荐学习过程：视频+黄飞海笔记=》自己的笔记，高质量完成作业。

本人学习过程：作业为主，视频和笔记为辅。

# W1：概论

作业：无
笔记：无

# W2：神经网络基础

作业：

# W3：浅层神经网络

作业：

# W4：深层神经网络

作业：


# 无监督学习

K-means

迭代算法，做两件事，
* 簇分配：检查所有的数据点，看数据点距离哪个聚类中心最近。
* 移动聚类中心：找到所有同类点，然后算出他们的中心作为新的聚类中心。

输入：k、一群无标签数据集

Kmeans的优化目标函数：失真代价函数，就是所有的点距离其聚类中心的距离的平方和的均值。

可以在数学上证明，这个簇分配的步骤就是最小化代价函数J。
移动聚类中心所做的就是选择u值来最小化J。

随即初始化：避免局部最优解。

随即初始化可能会局部最优解：可能将一个簇分为两个，把两个簇看做一个。

如何选择聚类数量？
很多都是手动。

不同的人观察，聚类数也是模棱两可的。

肘部原则：改变K，计算代价函数J。画出曲线，然后找拐点。

用Kmeans来市场分割等，根据目的给出一个评估标准，能更好的用于后续事件。比如我只把t恤分三种，那么K就等于3。



0
