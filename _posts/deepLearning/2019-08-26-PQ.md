---
layout: post
title: 基于乘积量化的近似最近邻算法
tags:
categories: deepLearning
description:
---

基于乘积量化的近似最近邻算法【陶津 王晓东 姚宇】

# 1 近似最近邻搜索问题

乘积量化 (Product Quantization, PQ) [1]是一种十分优秀的处理大规模数据的近似最近邻算法。每一条数据库中的向量都被量化成一段简短的PQ码, 通过按表查询 (Lookup tables) PQ码的方式来完成搜索。乘积量化算法具有三大优点:1) 乘积量化算法将输入向量压缩为一段短小的PQ码,比如64位PQ码, 使得该算法可以一次性处理十亿级别的数据量。2) 原始向量与PQ码的近似距离是通过非对称距离计算 (Asymmetric Distance Computation, ADC) 的方式计算的, 该方式很好地估计了原始向量的欧氏距离。3) 乘积向量所使用的数据结构以及编码方式都十分简单, 可以很方便地与其他索引结构聚合。

实际应用当中，如果采用L2距离搜索，数据量很大的时候，时间开销太大，而且要把所有的数据读取到内存中，这是不现实的。近似最近邻方法通过牺牲一些计算精度来获得更快的计算速度和更少的内存需求。比如N个数据的D维向量，线性搜索的时间复杂度是O(DN)，占用的内存空间是4DN字节（如果特征均采用32位浮点数表示）。



# 2 乘积量化算法PQ

法国国家信息与自动化研究所实验室的Jégou证明了:1) 乘积向量算法可以用来压缩高维特征向量;2) 原始向量与编码后的PQ码的距离足够接近;3) 通过乘积向量算法和倒排索引可以建立起一个快速搜索系统。

## 2.1 编码

一个D维向量可以看做由M个子向量连接而成，在训练阶段，对每一个子向量训练k个聚类中心。

输入向量的编码过程为：
* 首先将向量分为M段，对每一段，分别返回与其最接近的一个聚类中心，计算每一段时，将D/M维向量与k个聚类中心的距离依次解出，复杂度是O(DK/M)，因此整个向量编码的计算复杂度是O(DK)。
* 接下来将每一段输出的聚类中心连接到一起，即完成对输入向量的编码，原向量最终的量化空间就是聚类中心的笛卡尔成绩。

## 2.2 解码

乘积量化算法的一个优点是该算法可以从PQ码近似地还原出原始向量。

PQ码即M个聚类中心的连接，通过PQ码和码本找到对应的码字，该码字对应一个聚类中心的向量，将各个聚类中心的向量连接起来从而近似的还原原始向量。

## 2.3 内存消耗

乘积向量算法通过高度压缩比来确保计算出的PQ码都保存在内存中。PQ码由M个码字组成, 每个码字的取值范围为{1, 2, …, K}, 故每段PQ码的内存消耗为M lb K位。可以看出, 参数M和K影响了解码精度和内存消耗。如果每个整数使用无符号8位表示, 那么K一般设为256, 于是整段PQ码需要使用8M位来表示。M越大, 则计算精度越高, 但是计算性能则越差。

## 2.4 距离计算

每个向量对应一个PQ码，共有N个PQ码。

给定一个待查询的特征向量和一段PQ码, 通过非对称距离计算方法可以有效地计算出特征向量和PQ码所表示的原始向量的近似距离。计算分为两步：1) 建立距离查找表;2) 查找距离。

给定待查询向量y, 对y的每一段子向量ym∈RD/M, m∈{1, 2, …, M}, 分别计算出该段子向量ym与K个子码字ckm∈Cm的距离, 并将结果保存在一张距离表A:{1, 2, …, M}×{1, 2, …, K}→R中。

A可以用一个二维数组表示。建立表的操作一共需要O (DK) 的计算复杂度, 每次查询只需建立一次。

然后该向量与一个PQ码的距离只需要查表将m个距离数值相加即可，查询N个PQ码的复杂度是O(MN)。

总的来说，非对称距离计算可以无需将PQ码近似解码还原就可以计算出待查向量与PQ码对应的原向量的近似距离。

## 2.5 与倒排索引结合的搜素系统

基于非对称距离计算的线性查找比直接线性查找快了很多，但是当N很大的时候，速度依然不够快。为了处理百万级甚至十亿级数据量的查找，提出了一种结合了倒排索引的搜索系统。

在预处理阶段, N条数据库项χ={x1, x2, …, xN}被分为J个互斥组, χ1, χ2, …, χJ。每一组都有一个代表向量μj∈RD。每一组都计算出代表向量与其组内每一项数据x∈χj的残差。将残差x-μj编码成PQ码, 并存储为一张倒排链表。

在搜索阶段, 系统操作分别两步;粗量化和距离估计。

1) 粗量化:给定一个待查询向量y∈RD, 选择距离最近的组χj。计算出待查询向量与该组代表向量的残差y-μj。

2) 距离估计:通过遍历倒序链表可以得到选定组的PQ码。通过计算残差向量y-μj与这些PQ码的非对称距离, 可以求解最近邻问题。

上述方法中, 搜索空间被粗量化限定, 只计算选定的组内的数据项。

```
补充：[倒排索引 inverted index](https://blog.csdn.net/weixin_34306446/article/details/86233245)：
在搜索引擎中每个文件都对应一个文件ID，文件内容被表示为一系列关键词的集合（实际上在搜索引擎索引库中，关键词也已经转换为关键词ID）。例如“文档1”经过分词，提取了20个关键词，每个关键词都会记录它在文档中的出现次数和出现位置。
正向索引是指通过key去找value。当用户在主页上搜索关键词“华为手机”时，假设只存在正向索引（forward index），那么就需要扫描索引库中的所有文档，找出所有包含关键词“华为手机”的文档，再根据打分模型进行打分，排出名次后呈现给用户。因为互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。
所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。得到倒排索引的结构如下：“关键词1”：“文档1”的ID，“文档2”的ID，…………。即从关键词去找文档。
```

在基于倒排文件系统的非对称距离计算 (In Verted File system with the Asymmetric Distance Computation, IVFADC) 方法[1]中, 粗量化步骤只是一个简单的为代表向量寻找最近邻的问题。距离计算步骤是计算待查询向量与残差向量的非对称距离。这个方法可以在10~100 ms中完成N=109量级的搜索, 与基于局部敏感哈希的高维数据索引算法[7]相比, 在同等时间和召回率下, 查找速度提高了约1 000倍。

相似搜索的共有三大类方法：
* 基于树的方法
	* KD树是其下的经典算法。一般而言，在空间维度比较低时，KD树的查找性能还是比较高效的；但当空间维度较高时，该方法会退化为暴力枚举，性能较差，这时一般会采用下面的哈希方法或者矢量量化方法。
* 哈希方法
	* LSH(Locality-Sensitive Hashing)是其下的代表算法。文献[7]是一篇非常好的LSH入门资料。
	* 对于小数据集和中规模的数据集(几个million-几十个million)，基于LSH的方法的效果和性能都还不错。这方面有2个开源工具FALCONN和NMSLIB。
* 矢量量化方法
	* 矢量量化方法，即vector quantization。在矢量量化编码中，关键是码本的建立和码字搜索算法。比如常见的聚类算法，就是一种矢量量化方法。而在相似搜索中，向量量化方法又以PQ方法最为典型。
	* 对于大规模数据集(几百个million以上)，基于矢量量化的方法是一个明智的选择，可以用用Faiss开源工具。
