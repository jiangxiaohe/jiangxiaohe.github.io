---
layout: post
title: 关键帧提取
tags:
categories: deepLearning
description: 如何提取视频当中的关键帧，有哪些常用算法？图片之间的相似度如何比较
---

# 关键帧提取的应用场景

视频检索领域中视频数据存在数据量大、 维度高的特点，在检索过程中需要消耗大量的内存与搜索时间。

随着移动互联网的普及，对视频片段的搜索也具有重要的意义，例如： 根据某个视频片段检索出数据库中相似的视频集，该技术可作为许多应用的预处理步骤。

视频包含了空间域、时间域、剧情等信息，直接对视频进行特征提取与索引是极为复杂的工作，并且需要消耗大量的存储空间与计算时间。

大多数的方案对镜头每帧进行 **相似性的度量**，并与某个固定的阈值进行比较来选出关键帧[12]，然而该阈值确实难以确定，并且难以适合每个镜头。

首先计算镜头中所有帧的平均值，将平均值与向量平均值最为接近的帧作为关键帧，由此实现了自适应的关键帧提取。

在提取视频每个镜头关键帧之后，通过对视频帧进行基于内容的检索方案即可高效、准确地检索出相关的视频序列。

参考[梁建胜,温贺平,基于深度学习的视频关键帧提取与视频检索]



# 通过比较帧与帧之间的距离来确定关键帧

总的方法是帧间距离大于预设阈值保存为关键帧。常用的有帧间差分、直方图、光流场、

## 帧间差分法

背景：

摄像机采集的视频序列具有连续性的特点。如果场景内没有运动目标，则连续帧的变化很微弱，如果存在运动目标，则连续的帧和帧之间会有明显地变化。

该类算法对时间上连续的两帧或三帧图像进行差分运算，不同帧对应的像素点相减，判断灰度差的绝对值，当绝对值超过一定阈值时，即可判断为运动目标，从而实现目标的检测功能。

两帧差分法适用于目标运动较为缓慢的场景，当运动较快时，由于目标在相邻帧图像上的位置相差较大，两帧图像相减后并不能得到完整的运动目标，因此，人们在两帧差分法的基础上提出了三帧差分法。

帧间差分法的原理简单，计算量小，能够快速检测出场景中的运动目标。但由实验结果可以看出，帧间差分法检测的目标不完整，内部含有“空洞”，这是因为运动目标在相邻帧之间的位置变化缓慢，目标内部在不同帧图像中相重叠的部分很难检测出来。帧间差分法通常不单独用在目标检测中，往往与其它的检测算法结合使用。

`diff = cv.absdiff(frame,lastFrame)`

有三种基于帧间差分的方法：
1. 使用差分强度的顺序，对所有帧按照平均差分强度进行排序，选择平均帧间差分强度最高的若干张图片作为视频的关键帧
2. 使用平均帧间差分强度高于阈值的帧作为视频的关键帧
	* 具体可参考github项目：https://github.com/AllenAnthony/Key-Frame
3. 选择局部最大值,这种方法的提取结果在丰富度上表现更好一些，提取结果均匀分散在视频中
	* 具体可参考https://blog.csdn.net/u011583927/article/details/84842915

## 颜色直方图法

```
gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)# 提取灰度图像
hist = cv.calcHist([gray],[0],None,[256],[0,256])
diff = cv.absdiff(hist,lastHist)
```

## 光流场法

利用光流场法实现目标检测的基本思想是：首先计算图像中每一个像素点的运动向量，即建立整幅图像的光流场。如果场景中没有运动目标，则图像中所有像素点的运动向量应该是连续变化的；如果有运动目标，由于目标和背景之间存在相对运动，目标所在位置处的运动向量必然和邻域(背景)的运动向量不同，从而检测出运动目标。

通过计算光流场得到的像素运动向量是由目标和摄像机之间的相对运动产生的。因此该类检测方法可以适用于摄像机静止和运动两种场合。但是光流场的计算过于复杂，而且在实际情况中， 由于光线等因素的影响，目标在运动时，其表面的亮度并不是保持不变的，这就不满足光流基本约束方程的假设前提，导致计算会出现很大的误差。光流场法很少应用于实际的

参考：
* [帧间差分法、背景减法、光流场法](https://blog.csdn.net/zhang1308299607/article/details/80081553)

## 聚类法

https://blog.csdn.net/ZJU_fish1996/article/details/54135837

https://wenku.baidu.com/view/598512156bec0975f565e24d.html

## 感知哈希算法

那么如何判断一张被PS过的图片是否与另一张图片本质上相同呢？比较简单、易用的解决方案是采用感知哈希算法.

感知哈希算法是一类算法的总称，包括aHash、pHash、dHash。顾名思义，感知哈希不是以严格的方式计算Hash值，而是以更加相对的方式计算哈希值，因为“相似”与否，就是一种相对的判定。

* aHash：平均值哈希。速度比较快，但是常常不太精确。
* pHash：感知哈希。精确度比较高，但是速度方面较差一些。
* dHash：差异值哈希。Amazing！精确度较高，且速度也非常快。因此我就选择了dHash作为我图片判重的算法。

## PHash
https://blog.csdn.net/qq_23937195/article/details/88688512

基本思路就是：
灰度化
->压缩至同一尺寸（32*32）
->离散变换
->计算相似hash（指纹）
->计算汉明距

## DHash
https://www.jianshu.com/p/193f0089b7a2

如何判断是同一张图片呢？最简单的方法是使用加密哈希（例如MD5, SHA-1）判断。但是局限性非常大。例如一个txt文档，其MD5值是根据这个txt的二进制数据计算的，如果是这个txt文档的完全复制版，那他们的MD5值是完全相同的。但是，一旦改变副本的内容，哪怕只是副本的缩进格式，其MD5也会天差地别。因此加密哈希只能用于判断两个完全一致、未经修改的文件，如果是一张经过调色或者缩放的图片，根本无法判断其与另一张图片是否为同一张图片。

# I帧、P帧、B帧

## 什么是I帧,P帧,B帧

视频压缩中，每帧代表一幅静止的图像。而在实际压缩时，会采取各种算法减少数据的容量，其中IPB就是最常见的。
* I帧表示关键帧，你可以理解为这一帧画面的完整保留；解码时只需要本帧数据就可以完成（因为包含完整画面）
* P帧表示的是这一帧跟之前的一个关键帧（或P帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（也就是差别帧，P帧没有完整画面数据，只有与前一帧的画面差别的数据）
* B帧是双向差别帧，也就是B帧记录的是本帧与前后帧的差别（具体比较复杂，有4种情况），换言之，要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码时CPU会比较累~。

参考:https://blog.csdn.net/abcjennifer/article/details/6577934

## 问题
* IPB帧是和视频编码格式相关吗？avi、flv是否都存在IPB帧
* 每分钟一般有几个I帧
* 如何提取I帧
* 视频时间偏移后关键帧是否不变

https://www.jianshu.com/p/6c90f0513084

视频编解码器：https://zh.wikipedia.org/wiki/%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8

关于视频格式和编码格式的问题？
格式是一个容器，常见的格式包括AVI、MPG、WMV、MKV、TS、TP、RMVB、MOV、MP4、3GP、等等。
编码是向这个容器放入东西的方法、例如可以横放、竖放、侧放，等等。常见的编码包括H.261、H.263、H.264、MPEG4、MPEG2、mpeg1、xvid、divx、VC-1、wmv1~9、realvideo8~10等等。
常见的AVI主要由三种编码组成xvid、divx、h264，不常见的AVI还包括很多DV拍摄的视频，由于各个厂家不一样，所使用的编码也不一样。



00
