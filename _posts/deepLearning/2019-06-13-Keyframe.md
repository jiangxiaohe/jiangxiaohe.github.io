---
layout: post
title: 关键帧提取和帧间距离算法
tags:
categories: deepLearning
description: 介绍了关键帧提取的重要性，并介绍了传统的颜色直方图等计算帧间距离的方法，以及感知哈希算法。
---

[TOC]

# 关键帧提取作为视频摘要和视频检索的预处理步骤

视频检索领域中视频数据存在数据量大、 维度高的特点，在检索过程中需要消耗大量的内存与搜索时间。

随着移动互联网的普及，对视频片段的搜索也具有重要的意义，例如： 根据某个视频片段检索出数据库中相似的视频集，该技术可作为许多应用的预处理步骤。

总的方法是帧间距离大于预设阈值保存为关键帧，以下介绍帧间差分法。关于帧间距离（图片相似度度量）的描述有：颜色差值、颜色直方图差值、感知哈希等。

# 帧间差分法提取关键帧

背景：

摄像机采集的视频序列具有连续性的特点。如果场景内没有运动目标，则连续帧的变化很微弱，如果存在运动目标，则连续的帧和帧之间会有明显地变化。

该类算法对时间上连续的两帧或三帧图像进行差分运算，不同帧对应的像素点相减，判断灰度差的绝对值，当绝对值超过一定阈值时，即可判断为运动目标，从而实现目标的检测功能。

两帧差分法适用于目标运动较为缓慢的场景，当运动较快时，由于目标在相邻帧图像上的位置相差较大，两帧图像相减后并不能得到完整的运动目标，因此，人们在两帧差分法的基础上提出了三帧差分法。

帧间差分法的原理简单，计算量小，能够快速检测出场景中的运动目标。但由实验结果可以看出，帧间差分法检测的目标不完整，内部含有“空洞”，这是因为运动目标在相邻帧之间的位置变化缓慢，目标内部在不同帧图像中相重叠的部分很难检测出来。帧间差分法通常不单独用在目标检测中，往往与其它的检测算法结合使用。

`diff = cv.absdiff(frame,lastFrame)`

颜色直方图可以看做是帧间差分法的一种，只不过用的是颜色直方图之间的差值，而非颜色编码之间的差值。

```
gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)# 提取灰度图像
hist = cv.calcHist([gray],[0],None,[256],[0,256])
diff = cv.absdiff(hist,lastHist)
```

有三种基于帧间差分的提取关键帧的方法：
1. 使用差分强度的顺序，对所有帧按照平均差分强度进行排序，选择平均帧间差分强度最高的若干张图片作为视频的关键帧
2. 使用平均帧间差分强度高于阈值的帧作为视频的关键帧。[Github/AllenAnthony/Key-Frame](https://github.com/AllenAnthony/Key-Frame)
3. 选择局部最大值,这种方法的提取结果在丰富度上表现更好一些，提取结果均匀分散在视频中。[CSDN/随煜而安](https://blog.csdn.net/u011583927/article/details/84842915)

另外，针对运动目标检测，还有背景减弱法和光流场法。
* 背景减弱法：是当前运动目标检测技术中应用较为广泛的一类方法，它的基本思想和帧间差分法相类似，都是利用不同图像的差分运算提取目标区域。不过与帧间差分法不同的是，背景减法不是将当前帧图像与相邻帧图像相减，而是将当前帧图像与一个不断更新的背景模型相减，在差分图像中提取运动目标。
* [运动目标检测的帧间差分法、背景减法、光流场法简介](https://blog.csdn.net/zhang1308299607/article/details/80081553)

# 聚类法

对于视频中的各个图片，定义图片之间的相似度（如采用颜色直方图之间的差值），然后用聚类算法，聚类的中心即为关键帧。

聚类算法中，需要预定一个阈值来控制聚类的密度。在聚类过程中也可以加入约束条件，如每个聚类中的图像帧数目不应该太少或太多，每个聚类的质心不应该相似，也就是这些聚类质心的距离要大，还可以采用模糊聚类方法实现关键帧的提取。

[中国科学院大学-关键帧提取课件](https://wenku.baidu.com/view/598512156bec0975f565e24d.html)

# 基于深度学习的方法

大多数的方案对镜头每帧进行 **相似性的度量**，并与某个固定的阈值进行比较来选出关键帧，**然而该阈值确实难以确定，并且难以适合每个镜头**。

首先计算镜头中所有帧的平均值，将平均值与向量平均值最为接近的帧作为关键帧，由此实现了自适应的关键帧提取。

在提取视频每个镜头关键帧之后，通过对视频帧进行基于内容的检索方案即可高效、准确地检索出相关的视频序列。

参考[2019,梁建胜,温贺平,基于深度学习的视频关键帧提取与视频检索]

# 图片相似度度量

前面在帧间差分法一节中提到了用颜色差值和颜色直方图差值来度量图片相似度。

# 感知哈希算法

那么如何判断一张被PS过的图片是否与另一张图片本质上相同呢？比较简单、易用的解决方案是采用感知哈希算法.

感知哈希算法是一类算法的总称，包括aHash、pHash、dHash。顾名思义，感知哈希不是以严格的方式计算Hash值，而是以更加相对的方式计算哈希值，因为“相似”与否，就是一种相对的判定。

* aHash：平均值哈希。速度比较快，但是常常不太精确。
* pHash：感知哈希。精确度比较高，但是速度方面较差一些。
* dHash：差异值哈希。精确度较高，且速度也非常快。因此我就选择了dHash作为我图片判重的算法。

往往采用强大的pHash算法和SIFT算法，它们能够识别图片的变形。只要变形程度不超过25%，它们就能匹配原图。这些算法虽然更复杂，但是原理与上面的简便算法是一样的，就是先将图片转化成Hash字符串，然后再进行比较。

## [PHash](https://blog.csdn.net/qq_23937195/article/details/88688512)

基本思路就是：
灰度化->压缩至同一尺寸（32*32）->DCT变换->计算相似hash（指纹）->计算汉明距

```python
def p_hash(src):
    img = cv2.imread(src)
    hash_len = 32

    # 灰度
    gray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    # 压缩
    resize_gray_img = cv2.resize(gray_img,(hash_len,hash_len),interpolation=cv2.INTER_AREA)

    # 图像内的整型转为浮点数便于dct
    h, w = resize_gray_img.shape[:2]  # 获取图像宽高
    vis0 = numpy.zeros((h, w), numpy.float32)  # 初始化
    vis0[:h, :w] = resize_gray_img  # 填充数据

    # 离散余弦变换
    vis1 = cv2.dct(cv2.dct(vis0)) # 转换后仍然是32*32
    img_list = vis1.flatten() # img_list.shape (1024,)

    # 计算均值
    avg = sum(img_list) * 1. / len(img_list)
    avg_list = []
    for i in img_list:
        if i < avg:
            tmp = '0'
        else:
            tmp = '1'
        avg_list.append(tmp)

    # 计算哈希值，用16进制表示
    p_hash_str = ''
    for x in range(0, hash_len * hash_len, 4):
        p_hash_str += '%x' % int(''.join(avg_list[x:x + 4]), 2)
    return p_hash_str
```

## DHash

[基于dhash的暴力图片去重](https://blog.csdn.net/Gentle_Guan/article/details/73384767)

1. 通过listdir列出目录内文件，通过后缀集合(postFix)进行图片格式检查
2. 每个图片转换为灰度图片并压缩大小(8,9) 便于处理
3. 得到每个像素的value(0-255)
4. 每一个像素点与它左边的像素点进行比较，得到0或者1
5. 比较结果存入diff后放在allDiff中
6. 暴力比较每两张图片的汉明距离
7. 设定汉明距离的范围，得出重复图片

```python
width = 32
high = 32  # 压缩后的大小
dirName = ""  # 相册路径
allDiff = []
postFix = picPostfix()  #  图片后缀的集合

dirList = listdir(dirName)
cnt = 0
for i in dirList:
    cnt += 1
    print cnt  # 可以不打印 表示处理的文件计数
    if str(i).split('.')[-1] in postFix:  # 判断后缀是不是照片格式
        im = Image.open(r'%s\%s' % (dirName, unicode(str(i), "utf-8")))
        diff = getDiff(width, high, im)
        allDiff.append((str(i), diff))
# 暴力判断是否是相同图片
for i in range(len(allDiff)):
    for j in range(i + 1, len(allDiff)):
        if i != j:
            ans = getHamming(allDiff[i][1], allDiff[j][1])
            if ans <= 5:  # 判别的汉明距离，自己根据实际情况设置
                print allDiff[i][0], "and", allDiff[j][0], "maybe same photo..."

```


# I帧、P帧、B帧方法

[CSDN/abcjennifer](https://blog.csdn.net/abcjennifer/article/details/6577934)

视频压缩中，每帧代表一幅静止的图像。而在实际压缩时，会采取各种算法减少数据的容量，其中IPB就是最常见的。
* I帧表示关键帧，你可以理解为这一帧画面的完整保留；解码时只需要本帧数据就可以完成（因为包含完整画面）
* P帧表示的是这一帧跟之前的一个关键帧（或P帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（也就是差别帧，P帧没有完整画面数据，只有与前一帧的画面差别的数据）
* B帧是双向差别帧，也就是B帧记录的是本帧与前后帧的差别（具体比较复杂，有4种情况），换言之，要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码时CPU会比较累。

## 帧间管理

[简书/纳兰少](https://www.jianshu.com/p/6c90f0513084)

帧间的相似度使得视频传输过程中没必要传输所有的帧，帧间管理通常用关键帧和增量帧来实现，增量帧仅保存图像中的更改以减少冗余信息。这些帧的结合通常由GOP(Group of Pictures)来引用。用于编码或解码数字数据流的视频编解码器都具有某种形式的帧间管理。H.264,MPEG2,MPEG4都采用三帧方法，包括I、P、B帧。

[wikipedia视频编解码器](https://zh.wikipedia.org/wiki/%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8)

[视频编码与视频格式的区别和联系](https://www.cnblogs.com/yinxiangpei/articles/3501800.html)

视频编码是一种压缩技术，就是把原始的视频流压缩成特定的比特流（视编码方案）。视频格式是一种封装格式，就是把编码后的比特流进行封装，不同的视频格式封装方法不同。国际上标准的视频编码格式目前只有MPEG2/MPEG4/H.264/MJPEG这几种，所以其他的编码格式都是各个厂家的私有编码（例如微软的DIVX、real公司的RM系列等）
对应可以如下
（封装格式：编码格式）
* AVI：MPEG-2，DIVX，XVID，AC-1，H.264;
* WMV：WMV，AC-1;
* RM、RMVB：RV， RM;
* MOV：MPEG-2，XVID，H.264;
* TS/PS：MPEG-2，H.264，MPEG-4;

## 如何设置关键帧

关键帧间隔控制在视频中创建关键帧的频率，关键帧的频率越高，通常对内容应用的压缩越多，尽管这并不意味着质量明显下降。如果您的间隔设置为每2秒，并且您的帧速率为每秒30帧，则这意味着大约每60帧生成一个关键帧。

术语“关键帧间隔”不是通用的，大多数编码器都有自己的术语。例如，Adobe Flash Media Live Encoder（FMLE）和vMix使用术语“关键帧频率”来描述此过程。其他程序和服务可能将间隔称为“GOP大小”或“GOP长度”，返回“图片组”缩写。

在编码器级别可以选择设置关键帧间隔。

一般的关键帧设置为2s。如果设置了关键帧为10s，则意味着比特率和分辨率可能会发生变化需要等待10s，这段时间意味着内容可能会在更改发生之前缓冲在观看者一侧，这可能导致观看者放弃。

**IPB帧和我们所说的关键帧提取是不同的概念，生成的方式也不同，我们提取关键帧做视频特征提取，不能采用IPB帧的方式。**
