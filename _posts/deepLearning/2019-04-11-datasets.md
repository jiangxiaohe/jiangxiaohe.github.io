---
layout: post
title: 常用数据集介绍
tags:
categories: deepLearning
description: 经典数据集
---

[TOC]

# MNIST数据集

MNIST 数据集可在 `http://yann.lecun.com/exdb/mnist/` 获取, 它包含了四个部分:
* Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本)
* Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签)
* Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本)
* Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签)

MNIST 数据集来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST). 训练集 (training set) 由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员. 测试集(test set) 也是同样比例的手写数字数据.

# CIFAR-10

# COCO

COCO(Common Objects in Context)是一个新的图像识别、分割、和字幕数据集，它有如下特点：

* 对象分割、上下文识别、每个图像的多个对象、超过300000幅图像、超过200万个实例、80个对象类别、每个图像5个说明文字、100000人的关键点




# ImageNet数据集

从2010年开始,每年举办的ILSVRC图像分类和目标检测大赛。Imagenet数据集是目前深度学习图像领域应用得非常多的一个领域，关于图像分类、定位、检测等研究工作大多基于此数据集展开。Imagenet数据集文档详细，有专门的团队维护，使用非常方便，在计算机视觉领域研究论文中应用非常广，几乎成为了目前深度学习图像领域算法性能检验的“标准”数据集。Imagenet数据集有1400多万幅图片，涵盖2万多个类别；其中有超过百万的图片有明确的类别标注和图像中物体位置的标注。

[ImageNet官网地址](http://www.image-net.org/signup.php?next=download-images)

训练数据集和         验证数据集分别是两个tar文件ILSVRC2012_img_train.tar和ILSVRC2012_img_val.tar。将这两个文件拷贝至服务器合适的地址中（如/dataset/imagenet），对着两个文件分别解压到当前目录下。
ILSVRC2012_img_train.tar解压后是1000个tar文件，每个tar文件表示1000个分类中的一个类。需要对这1000个tar文件再次解压。在train目录下执行unzip.sh文件，最后得到1000个文件夹。每个文件夹中是该类的图片。ILSVRC2012_img_val.tar解压后的文件夹包含了所有的验证集图片。

[下载文件的详细信息](https://blog.csdn.net/fengbingchun/article/details/88606621)

[解压后的目录结构](https://blog.csdn.net/weixin_43896398/article/details/84762875)

# YouTube-8M 数据集

用的最多

https://blog.csdn.net/u010167269/article/details/52740990

https://research.google.com/youtube8m/

# google_landmark

数据集官网 https://www.kaggle.com/google/google-landmarks-dataset

特点：
*	它包含更多的类（在此挑战中总共有15K类），并且每个类的训练示例的数量可能不是很大
*	新数据集是全球最大的图像检索研究数据集，包含超过120w张独特地标图像350G
*	地标建筑不会有非刚性形变
*	官方提供开源的深度局部特征（DELF）以适用于次任务

你有没有看过你的假期照片并问自己：我在中国访问过这座寺庙的名字是什么？谁创造了我在法国看到的这座纪念碑？地标识别可以提供帮助！该技术可以直接从图像像素预测地标标签，以帮助人们更好地理解和组织他们的照片集。今天，地标识别研究的一个巨大障碍是缺乏大型注释数据集。这促使我们发布迄今为止最大的全球数据集Google-Landmarks，以促进这一问题的进展。
为了促进该领域的研究，我们拥有开源的深度局部特征（DELF），这是一种专注的本地特征描述符，我们认为它特别适用于此类任务。


# UQ_VIDEO数据集

宋景宽，易阳，黄子，沉恒涛，Richang Hong：实时大规模近似重复视频检索的多重特征哈希。ACM Multimedia，第423-432页，2011年。

http://staff.itee.uq.edu.au/shenht/UQ_VIDEO/

名为UQ_VIDEO的Combined Dataset 是我们自己创建的视频数据集，它将CC_WEB_VIDEO添加到我们从YouTube下载的视频中。

我们选择最受欢迎的400个查询来查询来自YouTube的视频。这些查询是从Google Zeitgeist中选择的。每年，Google都会检查全球各地用户在Google搜索中输入的数十亿条查询，以发现Google Zeitgeist Archives中保存的Zeitgeist。我们从2004年到2009年收集了Google Zeitgeist Archives，并选择了最受欢迎的400个查询来搜索YouTube。每个查询的下载视频数量最多为1000个。我们从2010年7月到2010年9月抓取了超过20万个YouTube视频。

过滤掉尺寸大于10M的视频后，合并数据集总共包含169,952个视频。据我们所知，这是用于实验目的的最大的Web视频数据集。我们从这些视频中进一步提取了3,305,525个关键帧。该数据集向公众发布，以便其他研究人员能够将其用作试验台。

# UQ_IMH数据集

宋景宽，杨洋，杨毅，黄子，沉恒涛：从异质数据源大规模检索的跨媒体哈希。ACM SIGMOD，第785-796页，2013年。

http://staff.itee.uq.edu.au/shenht/UQ_IMH/index.htm

在SIGMOD 2013中标题为“从异构数据源进行大规模检索的媒体间哈希”的工作中，使用了两个图像数据集和一个文本集合进行评估。图像数据集包括ImageNet语料库和NUS_WIDE图像集。对于文本数据集，我们从Web收集了一组Web文档。

1. NUS-WIDE是一个Web图像数据集，包含从Flickr下载的269,648个图像。为评估提供了81个语义概念的真实标记。删除没有标签的图像后，我们剩下267,465张图像。我们随机选择10,000张图像及其来自数据集的标签作为训练数据，以用于桥接以下图像数据集和文本文档数据集。剩下的257,465幅图像作为小图像数据集，用于实验中的测试。

2. ImageNet是根据WordNet层次结构组织的非常大的图像数据库，其中层次结构的每个节点由一组图像描绘。目前，他们每个节点平均有超过500个图像。我们使用NUS-WIDE数据集中提供的5,018个标签作为搜索ImageNet的关键字，最后得到2,904个同义词（或概念）。通过使用这些同义词作为查询，我们从ImageNet收集了大约240万个图像。随机选择来自每个synset的3个图像作为训练图像数据，并将其余图像作为用于测试的大图像数据集。
共有2,413,987张图片从imageNet下载。

3.使用Google搜索引擎抓取Web文档。从ImageNet获得的2,904个概念用作文本查询。对于每个查询，我们都会下载Google返回的前100个网页。然后，我们从每个查询的结果中随机选择3个Web文档作为训练文本数据，其余用于测试。
使用谷歌收集了240,903份文件。
