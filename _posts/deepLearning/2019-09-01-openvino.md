---
layout: post
title: openVino
tags:
categories: deepLearning
description: 用openvino加速机器学习推理过程
---

* [github:opencv/dldt](https://github.com/opencv/dldt)
* [openvino工具包官方文档](https://docs.openvinotoolkit.org/latest/index.html)


# [安装openVino](https://docs.openvinotoolkit.org/latest/_docs_install_guides_installing_openvino_linux.html)

* 下载tgz包并且解压
* 安装`sudo ./install_GUI.sh`或者`sudo ./install.sh`
* 安装依赖项`cd /opt/intel/openvino/install_dependencies`,`sudo -E ./install_openvino_dependencies.sh`
* 设置环境变量`source /opt/intel/openvino/bin/setupvars.sh`，永久增加设置，请将该命令添加到`~/.bashrc`文件

* 配置模型优化器Model Optimizer
  * Model Optimizer是基于Python的命令行工具，用于从流行的深度学习框架（例如Caffe，TensorFlow，Apache MXNet，ONNX和Kaldi）中导入经过训练的模型。
  * 模型优化器是英特尔OpenVINO发行版工具包的关键组件。如果不通过Model Optimizer运行模型，则无法对训练后的模型进行推断。当您通过模型优化器运行预训练的模型时，您的输出是网络的中间表示（IR）。中间表示是一对描述整个模型的文件：
    * .xml：描述网络拓扑
    * .bin：包含权重并偏置二进制数据
  * 配置优化器支持各种框架`cd /opt/intel/openvino/deployment_tools/model_optimizer/install_prerequisites`、`sudo ./install_prerequisites.sh`
* 运行脚本以验证安装（此部分是必需的。除了确认安装成功之外，演示脚本还执行其他步骤，例如将计算机设置为使用推理引擎示例。）具体请看官方教程
* **因为计算机没有英特尔GPU，所以不需要安装GPU部分**
* 不需要运行`英特尔神经计算棒`和`英特尔视觉加速器`的部分
* 运行示例应用程序
  * 建立神经网络模型（具体代码查看官网）
    * 此步骤是其他框架的模型转化为`xml`文件，而运行libfacedetection时已经有xml文件就不需要此步骤
    * 为模型创建目录
    * 运行模型优化器，将安装时附带的FP32 Squeezenet Caffe模型转化为优化的FP16中间表示
    * 该squeezenet1.1.labels文件包含ImageNet使用的类。包含此文件，以便推断结果显示文本而不是分类号。复制squeezenet1.1.labels到优化的模型位置
  * 运行示例应用程序（CPU）
    * `cd ~/inference_engine_samples_build/intel64/Release`
    * `./classification_sample_async -i /opt/intel/openvino/deployment_tools/demo/car.png -m /home/<user>/squeezenet1.1_FP16/squeezenet1.1.xml -d CPU`

# 运行并修改目标检测例程

**任务**：修改官方例程中目标检测的代码，使其适用于人脸检测。

## 复制官方例程

* 运行完安装步骤后，会在主目录下面生成示例文件夹，其中inference_engine_demos_build、inference_engine_samples_build，都已经编译过了，编译后的程序在目录下面的intel64/Release目录之下。
* 编译这些示例的源码都在/opt/intel/openvino/inference_engine/之下，里面的demos和samples文件夹编译后生成主目录下面的编译文件。
* 因为文件在samples文件夹中，所以复制该文件夹到项目目录`~/Face/openvinoTest/`
* 删除除了object_detection_sample_ssd以外的项目文件夹
* 编译时直接运行samples文件夹下面的脚本`build_samples.sh`，注意修改该文件中的参数`build_dir`为`$HOME/Face/openvinoTest/sample/build`，否则默认的参数会覆盖主目录下面的编译文件夹
* 运行程序`build/intel64/Release/object_detection_sample_ssd`，设置参数`-i image`和参数`-m model.xml`和`-d CPU`

`./object_detection_sample_ssd -i /home/niyunsheng/Face/libfacedetection/images/keliamoniz1.jpg -m /home/niyunsheng/Face/libfacedetection/models/openvino/yufacedetectnet-open-v1-320x240.xml -d CPU`

* 输出文件`out_0.bmp`，这个在main函数中写死了，不能通过参数修改。

### main程序分析
共有11个步骤
1. 输入参数的解析和验证
2. 处理输入
3. 加载推理模型
4. 用模型优化器读取模型的中间表示(Intermediate Representation, IR)(.xml 和 .bin 文件)
5. 处理输入blobs（还不太理解指什么？）
6. 准备输出blobs
7. 载入模型到设备
8. 创建推理请求
9. 输入预处理
10. 模型推理
11. 处理模型输出

问题：
* 在测试fps时，我在第10步模型推理处增加了循环选项，用上面的命令测试出的fps为500，令人困惑的是这个数值多次测试一点也没有变化。
* 而且，用openvino生成的图片和libfacedetection生成的图片略有不同

* libfacedetection例程输出的图片
![libfacedetection例程输出的图片](http://cdn.niyunsheng.top/keliamoniz1_libfacedetection.jpg)
* openvino例程输出图片
![openvino例程输出图片](http://cdn.niyunsheng.top/keliamoniz1_openvino.bmp)

# [官方HELLO World人脸检测教程](https://github.com/intel-iot-devkit/inference-tutorials-generic/blob/openvino_toolkit_2019_r1_0/face_detection_tutorial/Readme.md)

在github上下载源码

## step 1 创建基本opencv应用程序

* 包括从摄像头或者文件夹读取图片

## step 2 添加人脸检测模型


此步骤暂时运行出错，未解决
