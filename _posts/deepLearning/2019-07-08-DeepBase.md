---
---
layout: post
title: 机器学习评价指标
tags:
categories: deepLearning
description: 召回率（Recall），精确率（Precision），平均正确率（Average_precision(AP) ），mAP
---

[TOC]

# [强化学习](https://blog.csdn.net/hellocsz/article/details/80835542)

机器学习可以分为三类，分别是 supervised learning，unsupervised learning 和reinforcement learning。而强化学习与其他机器学习不同之处为：
* 没有教师信号，也没有label。只有reward，其实reward就相当于label。
* 反馈有延时，不是能立即返回。
* 相当于输入数据是序列数据。
* agent执行的动作会影响之后的数据。

强化学习解决的问题是，针对一个具体问题得到一个最优的policy，使得在该策略下获得的reward最大。所谓的policy其实就是一系列action。也就是sequential data。 

# 评价指标

[YOLO学习笔记之评价指标](https://blog.csdn.net/shangpapa3/article/details/76177830)

假设现在有这样一个测试集，测试集中的图片只由大雁和飞机两种图片组成.

预测可能有四种结果：
* True positives : 飞机的图片被正确的识别成了飞机。
* True negatives: 大雁的图片没有被识别出来，系统正确地认为它们是大雁。
* False positives: 大雁的图片被错误地识别成了飞机。
* False negatives: 飞机的图片没有被识别出来，系统错误地认为它们是大雁。

positives和negatives分别代表预测是正类还是负类，true和false分别代表预测的正确性。

## Precision、Recall

$ Precision = \frac{tp}{tp+fp} $ 表示在识别为飞机的图片当中，飞机的照片所占的比例。

$ recall = \frac{tp}{tp+fn} $ 表示所有的飞机当中，被正确识别的比例。

一般来说，precision和recall负相关。通过改变阈值，会导致两者变化。如果想要评估一个分类器的性能，一个比较好的办法是：观察当阈值变化时，Precision与Recall值的变化情况。如果一个分类器的性能比较好，那么它应该有如下的表现：被识别出的图片中飞机所占的比重比较大，并且在识别出大雁之前，尽可能多地正确识别出飞机，也就是让Recall值增长的同时保持Precision的值在一个很高的水平。而性能比较差的分类器可能会损失很多Precision值才能换来Recall值的提高。通常情况下，文章中都会使用 **Precision-recall曲线**，来显示出分类器在Precision与Recall之间的权衡。

![](https://img-blog.csdn.net/20170105154145685?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaHlzdGVyaWMzMTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

上图就是分类器的Precision-recall 曲线，在不损失精度的条件下它能达到40%Recall。而当Recall达到100%时，Precision 降低到50%。

## AP

如果想要用一个数值而非曲线图来表示一个分类器的性能，通常用Average Precision来作为这一度量标准。

$ AP = \int_0^1{p(r)}dr $

P(r)代表正确率，r代表召回率。这个数值和P-R曲线下的面积相等。这一积分极其接近这一数值：对每一种阈值分别求Precision，乘以Recall的变化情况，再把所有阈值下求得的乘积值进行累加。

$ AP = \sum_{k=1}^N{p(k)}\Delta r(k) $

另一种度量性能的标准：Interpolated Average Precision。

$ IAP = \sum_{k=1}^N{max_{k'>=k}{P(k')}}\Delta r(k) $

![](https://img-blog.csdn.net/20170727110953087?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2hhbmdwYXBhMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## F-feature

最常见的方法应该是F-Measure，也称F-Score，是Precision和Recall的加权平均。

$ F = \frac{(a^2+1)P*R}{a^2(P+R)} $

当a=1时，就是最常见的F1了：

$ F1 = \frac{2PR}{P+R} $

当F1较高时则比较说明试验方法比较理想。

## [mAP](https://blog.csdn.net/u014203453/article/details/77598997)

多标签图像分类任务中图片的标签不止一个，因此评价不能用普通单标签图像分类的标准，即mean accuracy，该任务采用的是和信息检索中类似的方法—mAP（mean Average Precision），虽然其字面意思和mean accuracy看起来差不多，但是计算方法要繁琐得多，步骤如下：
1. 保存所有样本的confidence score
2. 对confidence score进行排序
3. 计算precision和recall
4. 计算AP

> 待具体搞懂！！

# [kernel function](https://blog.csdn.net/baimafujinji/article/details/79372911)

普通的SVM分类超平面只能应对线性可分的情况，而对于线性不可分的情况，我们需要引入一个kernel，这个kernel可以把数据集从低维映射到高维，使得原来线性不可分的数据集变得线性可分。

举例：原来在二维空间的椭圆内的点和外的点不能通过平面分开，设计一个feature mapping，将原来的二维特征空间转换到新的三维特征空间中，然后在三维空间中，用一个分隔超平面可将原来的两组数据分开。即原本线性不可分的数据通过kernel变得线性可分。

![](https://img-blog.csdn.net/20180226054706213)

在一个Hilbert空间中，最重要的运算是内积，在新的空间中，如何利用原空间中的信息计算新空间的内积？

可以发现，新空间中两个点的内积，可以通过一个关于原空间中内积的函数来得到，我们就定义这样的一个函数为核函数（kernel function）。

![](https://img-blog.csdn.net/20180226064108660)

最重要的在于，并不需要知道feature mapping到底是什么，只要知道K ，就可以通过原空间中两个点的内积算得新空间中对应的两个点的内积。

第二个例子，对于一个Polynomial kernel，注意其中的x和y是两个向量，

$\forall x, y \in \mathbb{R}^{N}, K(x, y)=(x \cdot y+c)^{d}, \quad c>0$

便可以计算新空间中x和y对应的两个点的内积：

$\begin{aligned} K(x, y) &=\left(x_{1} y_{1}+x_{2} y_{2}+c\right)^{2} \\ &=\left[\begin{array}{c}{x_{1}^{2}} \\ {x_{2}^{2}} \\ {\sqrt{2 c} x_{1}} \\ {\sqrt{2 c} x_{1}} \\ {c}\end{array}\right] & \cdot\left[\begin{array}{c}{\sqrt{2 c} y_{1}} \\ {\sqrt{2 c} y_{1}} \\ {\sqrt{2 c} y_{2}} \\ {c}\end{array}\right] \end{aligned}$

而且它同样具有“使得原本线性不可分的数据集在新空间中线性可分”的能力（这里仅仅用了新空间中的两个维度）

![](https://img-blog.csdn.net/20180226071035823)

常用的kernel function如下图所示，值得注意的是 RBF Kernel（高斯核）是一个典型的会将原空间投影到无穷维空间的核函数。关于这些核的具体讨论，请参考[李宏毅博士的在线授课视频](https://www.youtube.com/watch?v=QSEPStBgwRQ&index=29&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49)

![](https://img-blog.csdn.net/20180226071401524)

# [Batch Normalization批标准化](https://www.cnblogs.com/guoyaohua/p/8724433.html)

机器学习领域有个很重要的假设：IID独立同分布假设，就是假设训练数据和测试数据是满足相同分布的，这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。那BatchNorm的作用是什么呢？BatchNorm就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的。

为什么深度神经网络随着网络深度加深，训练起来越困难，收敛越来越慢？这是个在DL领域很接近本质的好问题。很多论文都是解决这个问题的，比如ReLU激活函数，再比如Residual Network，BN本质上也是解释并从某个不同的角度来解决这个问题的。

BN的基本思想其实相当直观：因为深层神经网络在做非线性变换前的激活输入值（就是那个x=WU+B，U是输入）随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（对于Sigmoid函数来说，意味着激活输入值WU+B是大的负值或正值），所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因，而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，意思是这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。

经过BN后，目前大部分Activation的值落入非线性函数的线性区内，其对应的导数远离导数饱和区，这样来加速训练收敛过程。

我们知道，如果是多层的线性函数变换其实这个深层是没有意义的，因为多层线性网络跟一层线性网络是等价的。这意味着网络的表达能力下降了，这也意味着深度的意义就没有了。所以BN为了保证非线性的获得，对变换后的满足均值为0方差为1的x又进行了scale加上shift操作(y=scale*x+shift)，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，意思是通过scale和shift把这个值从标准正态分布左移或者右移一点并长胖一点或者变瘦一点，每个实例挪动的程度不一样，这样等价于非线性函数的值从正中心周围的线性区往非线性区动了动。核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢。

如何实现：在要对每个隐层神经元的激活值做BN，可以想象成每个隐层又加上了一层BN操作层，它位于X=WU+B激活值获得之后，非线性函数变换之前。对于Mini-Batch SGD来说，一次训练过程里面包含m个训练实例，其具体BN操作就是对于隐层内每个神经元的激活值来说，进行如下变换：即归一化操作。

# [Batch 和 Epoch](https://blog.csdn.net/weixin_42137700/article/details/84302045)

Sample是单行数据。它包含输入到算法中的输入和用于与预测进行比较并计算错误的输出。训练数据集由许多行数据组成，例如许多Sample。Sample也可以称为实例，观察，输入向量或特征向量。

Batch大小是一个超参数，用于定义在更新内部模型参数之前要处理的样本数。将批处理视为循环迭代一个或多个样本并进行预测。在批处理结束时，将预测与预期输出变量进行比较，并计算误差。从该错误中，更新算法用于改进模型，例如沿误差梯度向下移动。训练数据集可以分为一个或多个Batch。当所有训练样本用于创建一个Batch时，学习算法称为批量梯度下降。当批量是一个样本的大小时，学习算法称为随机梯度下降。当批量大小超过一个样本且小于训练数据集的大小时，学习算法称为小批量梯度下降。在小批量梯度下降的情况下，流行的批量大小包括32,64和128个样本。

Epoch数是一个超参数，它定义了学习算法在整个训练数据集中的工作次数。一个Epoch意味着训练数据集中的每个样本都有机会更新内部模型参数。Epoch由一个或多个Batch组成。例如，如上所述，具有一批的Epoch称为批量梯度下降学习算法。您可以将for循环放在每个需要遍历训练数据集的epoch上，在这个for循环中是另一个嵌套的for循环，它遍历每批样本，其中一个批次具有指定的“批量大小”样本数。

epochs 数量传统上很大，通常是数百或数千，允许学习算法运行直到模型的误差被充分地最小化了。您可能会看到文献和教程设置为10,100,500,1000和更大的时期数量的示例。通常创建线图，其显示沿x轴的时间以及模型在y轴上的误差或技能。这些图有时被称为学习曲线。这些图可以帮助诊断模型是否已经过度学习，学习不足或者是否适合训练数据集。

> 两层循环的含义？

# [ImageNet 中的Top-1与Top-5](https://www.jianshu.com/p/46e812c1d670)

ImageNet 项目是一个用于物体对象识别检索大型视觉数据库。截止2016年，ImageNet 已经对超过一千万个图像进行手动注释，标记图像的类别。在至少一百万张图像中还提供了边界框。自2010年以来，ImageNet 举办一年一度的软件竞赛，叫做（ImageNet Large Scale Visual Recognition Challenge,ILSVRC)。主要内容是通过算法程序实现正确分类和探测识别物体与场景，评价标准就是Top-5 错误率。

Top-5错误率:即对一个图片，如果概率前五中包含正确答案，即认为正确。

Top-1错误率:即对一个图片，如果概率最大的是正确答案，才认为正确。

# ground truth

[参考](https://blog.csdn.net/FrankieHello/article/details/80486167)

经常会看到Ground Truth这个词汇，翻译的意思是地面实况，放到机器学习里面，再抽象点可以把它理解为真值、真实的有效值或者是标准的答案。


# Triplet Loss 损失函数

```python
class TripletMarginLoss(Module):
    Args:
        anchor: anchor input tensor
        positive: positive input tensor
        negative: negative input tensor
        p: the norm degree. Default: 2
    Shape:
        - Input: :math:`(N, D)` where `D = vector dimension`
        - Output: :math:`(N, 1)`
```

Triplet Loss是深度学习中的一种损失函数，用于训练差异性较小的样本，如人脸等， Feed数据包括锚（Anchor）示例、正（Positive）示例、负（Negative）示例，通过优化锚示例与正示例的距离小于锚示例与负示例的距离，实现样本的相似性计算。即与正样本之间的距离尽可能的小，与负样本的距离尽可能的大,并且要让x_a与x_n之间的距离和x_a与x_p之间的距离之间有一个最小的间隔.

$\sum_{i}^{N}\left[\left\|f\left(x_{i}^{a}\right)-f\left(x_{i}^{p}\right)\right\|_{2}^{2}-\left\|f\left(x_{i}^{a}\right)-f\left(x_{i}^{n}\right)\right\|_{2}^{2}+\alpha\right]_{+}$

这里距离用欧式距离度量，+表示[]内的值大于零的时候，取该值为损失，小于零的时候，损失为零。


0
