---
---
layout: post
title: 机器学习评价指标
tags:
categories: deepLearning
description: 召回率（Recall），精确率（Precision），平均正确率（Average_precision(AP) ），mAP
---

[TOC]

# 评价指标

[YOLO学习笔记之评价指标](https://blog.csdn.net/shangpapa3/article/details/76177830)

假设现在有这样一个测试集，测试集中的图片只由大雁和飞机两种图片组成.

预测可能有四种结果：
* True positives : 飞机的图片被正确的识别成了飞机。
* True negatives: 大雁的图片没有被识别出来，系统正确地认为它们是大雁。
* False positives: 大雁的图片被错误地识别成了飞机。
* False negatives: 飞机的图片没有被识别出来，系统错误地认为它们是大雁。

positives和negatives分别代表预测是正类还是负类，true和false分别代表预测的正确性。

## Precision、Recall

$ Precision = \frac{tp}{tp+fp} $ 表示在识别为飞机的图片当中，飞机的照片所占的比例。

$ recall = \frac{tp}{tp+fn} $ 表示所有的飞机当中，被正确识别的比例。

一般来说，precision和recall负相关。通过改变阈值，会导致两者变化。如果想要评估一个分类器的性能，一个比较好的办法是：观察当阈值变化时，Precision与Recall值的变化情况。如果一个分类器的性能比较好，那么它应该有如下的表现：被识别出的图片中飞机所占的比重比较大，并且在识别出大雁之前，尽可能多地正确识别出飞机，也就是让Recall值增长的同时保持Precision的值在一个很高的水平。而性能比较差的分类器可能会损失很多Precision值才能换来Recall值的提高。通常情况下，文章中都会使用 **Precision-recall曲线**，来显示出分类器在Precision与Recall之间的权衡。

![](https://img-blog.csdn.net/20170105154145685?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaHlzdGVyaWMzMTQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

上图就是分类器的Precision-recall 曲线，在不损失精度的条件下它能达到40%Recall。而当Recall达到100%时，Precision 降低到50%。

## AP

如果想要用一个数值而非曲线图来表示一个分类器的性能，通常用Average Precision来作为这一度量标准。

$ AP = \int_0^1{p(r)}dr $

P(r)代表正确率，r代表召回率。这个数值和P-R曲线下的面积相等。这一积分极其接近这一数值：对每一种阈值分别求Precision，乘以Recall的变化情况，再把所有阈值下求得的乘积值进行累加。

$ AP = \sum_{k=1}^N{p(k)}\Delta r(k) $

另一种度量性能的标准：Interpolated Average Precision。

$ IAP = \sum_{k=1}^N{max_{k'>=k}{P(k')}}\Delta r(k) $

![](https://img-blog.csdn.net/20170727110953087?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2hhbmdwYXBhMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## F-feature

最常见的方法应该是F-Measure，也称F-Score，是Precision和Recall的加权平均。

$ F = \frac{(a^2+1)P*R}{a^2(P+R)} $

当a=1时，就是最常见的F1了：

$ F1 = \frac{2PR}{P+R} $

当F1较高时则比较说明试验方法比较理想。

## [mAP](https://blog.csdn.net/u014203453/article/details/77598997)

多标签图像分类任务中图片的标签不止一个，因此评价不能用普通单标签图像分类的标准，即mean accuracy，该任务采用的是和信息检索中类似的方法—mAP（mean Average Precision），虽然其字面意思和mean accuracy看起来差不多，但是计算方法要繁琐得多，步骤如下：
1. 保存所有样本的confidence score
2. 对confidence score进行排序
3. 计算precision和recall
4. 计算AP

> 待具体搞懂！！

# [kernel function](https://blog.csdn.net/baimafujinji/article/details/79372911)

普通的SVM分类超平面只能应对线性可分的情况，而对于线性不可分的情况，我们需要引入一个kernel，这个kernel可以把数据集从低维映射到高维，使得原来线性不可分的数据集变得线性可分。

举例：原来在二维空间的椭圆内的点和外的点不能通过平面分开，设计一个feature mapping，将原来的二维特征空间转换到新的三维特征空间中，然后在三维空间中，用一个分隔超平面可将原来的两组数据分开。即原本线性不可分的数据通过kernel变得线性可分。

![](https://img-blog.csdn.net/20180226054706213)

在一个Hilbert空间中，最重要的运算是内积，在新的空间中，如何利用原空间中的信息计算新空间的内积？

可以发现，新空间中两个点的内积，可以通过一个关于原空间中内积的函数来得到，我们就定义这样的一个函数为核函数（kernel function）。

![](https://img-blog.csdn.net/20180226064108660)

最重要的在于，并不需要知道feature mapping到底是什么，只要知道K ，就可以通过原空间中两个点的内积算得新空间中对应的两个点的内积。

第二个例子，对于一个Polynomial kernel，注意其中的x和y是两个向量，

$\forall x, y \in \mathbb{R}^{N}, K(x, y)=(x \cdot y+c)^{d}, \quad c>0$

便可以计算新空间中x和y对应的两个点的内积：

$\begin{aligned} K(x, y) &=\left(x_{1} y_{1}+x_{2} y_{2}+c\right)^{2} \\ &=\left[\begin{array}{c}{x_{1}^{2}} \\ {x_{2}^{2}} \\ {\sqrt{2 c} x_{1}} \\ {\sqrt{2 c} x_{1}} \\ {c}\end{array}\right] & \cdot\left[\begin{array}{c}{\sqrt{2 c} y_{1}} \\ {\sqrt{2 c} y_{1}} \\ {\sqrt{2 c} y_{2}} \\ {c}\end{array}\right] \end{aligned}$

而且它同样具有“使得原本线性不可分的数据集在新空间中线性可分”的能力（这里仅仅用了新空间中的两个维度）

![](https://img-blog.csdn.net/20180226071035823)

常用的kernel function如下图所示，值得注意的是 RBF Kernel（高斯核）是一个典型的会将原空间投影到无穷维空间的核函数。关于这些核的具体讨论，请参考[李宏毅博士的在线授课视频](https://www.youtube.com/watch?v=QSEPStBgwRQ&index=29&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49)

![](https://img-blog.csdn.net/20180226071401524)

# [Batch 和 Epoch](https://blog.csdn.net/weixin_42137700/article/details/84302045)

Sample是单行数据。它包含输入到算法中的输入和用于与预测进行比较并计算错误的输出。训练数据集由许多行数据组成，例如许多Sample。Sample也可以称为实例，观察，输入向量或特征向量。

Batch大小是一个超参数，用于定义在更新内部模型参数之前要处理的样本数。将批处理视为循环迭代一个或多个样本并进行预测。在批处理结束时，将预测与预期输出变量进行比较，并计算误差。从该错误中，更新算法用于改进模型，例如沿误差梯度向下移动。训练数据集可以分为一个或多个Batch。当所有训练样本用于创建一个Batch时，学习算法称为批量梯度下降。当批量是一个样本的大小时，学习算法称为随机梯度下降。当批量大小超过一个样本且小于训练数据集的大小时，学习算法称为小批量梯度下降。在小批量梯度下降的情况下，流行的批量大小包括32,64和128个样本。

Epoch数是一个超参数，它定义了学习算法在整个训练数据集中的工作次数。一个Epoch意味着训练数据集中的每个样本都有机会更新内部模型参数。Epoch由一个或多个Batch组成。例如，如上所述，具有一批的Epoch称为批量梯度下降学习算法。您可以将for循环放在每个需要遍历训练数据集的epoch上，在这个for循环中是另一个嵌套的for循环，它遍历每批样本，其中一个批次具有指定的“批量大小”样本数。

epochs 数量传统上很大，通常是数百或数千，允许学习算法运行直到模型的误差被充分地最小化了。您可能会看到文献和教程设置为10,100,500,1000和更大的时期数量的示例。通常创建线图，其显示沿x轴的时间以及模型在y轴上的误差或技能。这些图有时被称为学习曲线。这些图可以帮助诊断模型是否已经过度学习，学习不足或者是否适合训练数据集。

> 两层循环的含义？

# [ImageNet 中的Top-1与Top-5](https://www.jianshu.com/p/46e812c1d670)

ImageNet 项目是一个用于物体对象识别检索大型视觉数据库。截止2016年，ImageNet 已经对超过一千万个图像进行手动注释，标记图像的类别。在至少一百万张图像中还提供了边界框。自2010年以来，ImageNet 举办一年一度的软件竞赛，叫做（ImageNet Large Scale Visual Recognition Challenge,ILSVRC)。主要内容是通过算法程序实现正确分类和探测识别物体与场景，评价标准就是Top-5 错误率。

Top-5错误率:即对一个图片，如果概率前五中包含正确答案，即认为正确。

Top-1错误率:即对一个图片，如果概率最大的是正确答案，才认为正确。

# ground truth

[参考](https://blog.csdn.net/FrankieHello/article/details/80486167)

经常会看到Ground Truth这个词汇，翻译的意思是地面实况，放到机器学习里面，再抽象点可以把它理解为真值、真实的有效值或者是标准的答案。


# Triplet Loss 损失函数

```python
class TripletMarginLoss(Module):
    Args:
        anchor: anchor input tensor
        positive: positive input tensor
        negative: negative input tensor
        p: the norm degree. Default: 2
    Shape:
        - Input: :math:`(N, D)` where `D = vector dimension`
        - Output: :math:`(N, 1)`
```

Triplet Loss是深度学习中的一种损失函数，用于训练差异性较小的样本，如人脸等， Feed数据包括锚（Anchor）示例、正（Positive）示例、负（Negative）示例，通过优化锚示例与正示例的距离小于锚示例与负示例的距离，实现样本的相似性计算。即与正样本之间的距离尽可能的小，与负样本的距离尽可能的大,并且要让x_a与x_n之间的距离和x_a与x_p之间的距离之间有一个最小的间隔.

$\sum_{i}^{N}\left[\left\|f\left(x_{i}^{a}\right)-f\left(x_{i}^{p}\right)\right\|_{2}^{2}-\left\|f\left(x_{i}^{a}\right)-f\left(x_{i}^{n}\right)\right\|_{2}^{2}+\alpha\right]_{+}$

这里距离用欧式距离度量，+表示[]内的值大于零的时候，取该值为损失，小于零的时候，损失为零。


0
