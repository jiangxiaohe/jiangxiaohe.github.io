---
layout: post
title: cuda配置、例程
tags:
categories: deepLearning
description: 实验笔记
---

# 安装cuda

在Ubuntu16.04上安装CUDA9.0

有很多坑，主要参考文章：

[简书deb](https://www.jianshu.com/p/71bc5f02ecd2)
[CSDN](https://blog.csdn.net/qlulibin/article/details/78714596)
[简书](https://www.jianshu.com/p/7acb5688f2dd)

[官方文档](https://developer.download.nvidia.cn/compute/cuda/9.0/Prod/docs/sidebar/CUDA_Installation_Guide_Linux.pdf)

# 在线deb包安装方式
**亲测没有问题**

1. 禁用nouveau驱动

```
1创建并修改文件
sudo vim /etc/modprobe.d/blacklist-nouveau.conf
2在文本中输入：
blacklist nouveau
options nouveau modeset=0
3执行生效
sudo update-initramfs -u
4查看是否关闭
lsmod | grep nouveau
若无内容输出，则成功关闭，往往要重启下才行
```

2. 验证系统是否安装了GCC
`gcc --version`

3. 验证系统是否安装了kernel header和 package development（若这里未安装安装后需要重启并ctrl+alt+F1进入命令行界面，不要登录用户界面
`uname -r`
`sudo apt-get install linux-headers-$(uname -r)`

4. 关闭图形界面
`sudo service lightdm stop`
`service --status-all | grep lightdm`

5. [在线deb方式安装cuda](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork)
	* 上述官网下载在线安装脚本
	* sudo dpkg -i cuda-repo-ubuntu1604_10.1.168-1_amd64.deb
	* sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/
	compute/cuda/repos/<distro>/<architecture>/7fa2af80.pub
	* sudo apt-get update
	* sudo apt-get install cuda-9.0
	* **这里一定要加9.0，第一次没有加，直接安装了最新版10.1**
	* 卸载10.1命令：sudo apt-get remove cuda、sudo apt autoremove
6. 检查Device Node Verification：`ls /dev/nvidia*`正确显示结果是`/dev/nvidia0       /dev/nvidiactl       /dev/nvidia-uvm`
	* 如果出现结果`ls: cannot access/dev/nvidia*: No such file or directory`，则需要编辑文件`sudo vi /etc/rc.local`。初次打开是空的，加入以下内容：

```
#!/bin/bash
/sbin/modprobe nvidia
if [ "$?" -eq 0 ]; then
 # Count the number of NVIDIA controllers found.
 NVDEVS=`lspci | grep -i NVIDIA`
 N3D=`echo "$NVDEVS" | grep "3D controller" | wc -l`
 NVGA=`echo "$NVDEVS" | grep "VGA compatible controller" | wc -l`
 N=`expr $N3D + $NVGA - 1`
 for i in `seq 0 $N`; do
 mknod -m 666 /dev/nvidia$i c 195 $i
 done
 mknod -m 666 /dev/nvidiactl c 195 255
else
 exit 1
fi
/sbin/modprobe nvidia-uvm
if [ "$?" -eq 0 ]; then
 # Find out the major device number used by the nvidia-uvm driver
 D=`grep nvidia-uvm /proc/devices | awk '{print $1}'`
 mknod -m 666 /dev/nvidia-uvm c $D 0
else
 exit 1
fi
```

7. 设置环境变量`sudo vim /etc/profile`.在结尾加入两行：

```
export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64\
${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
```
重启电脑，检查上述的环境变量是否设置成功

8. 验证驱动版本：`cat /proc/driver/nvidia/version`
9. 验证CUDA Toolkit：`nvcc -V`
10. 尝试编译cuda提供的例子。
	* 先下载例子cuda-install-samples-9.0.sh <dir>
	* 在NVIDIA_CUDA-9.0_Samples下make。系统就会自动进入到编译过程，整个过程大概需要十几到二十分钟，请耐心等待。如果出现错误的话，系统会立即报错停止。如果编译成功，最后会显示Finished building CUDA samples
	* cd /home/xxx/cuda_samples/NVIDIA_CUDA-9.0_Samples/bin/x86_64/linux/release
	* ./deviceQuery和./bandwidthTest命令均显示PASS则表示成功
11. 查看cuda版本cat /usr/local/cuda/version.txt

# run文件方法
**该方法试了不行，不知道哪里出问题，nvidia-smi找不到驱动**
走了一些弯路，记录如下

1. 安装cuda并不需要更换linux内核，更换的步骤如下：
需要更换Linux内核，我的当前内核版本为4.15，需要换到4.4
* `uname -a`查看当前使用的内核版本
* 查看当前内核版本`dpkg -l|grep linux-image`
* 查看可以更新的内核版本`sudo apt-cache search linux-image`
* 安装新内核
* `sudo apt-get install linux-image-4.4.0-77-generic linux-image-extra-4.4.0-77-generic`
* 更新grub引导`sudo update-grub`
* 重启进入ubuntu高级选项
* 若开机没有进入grub引导界面，需要设置配置文件
	* `sudo vim /etc/default/grub`
	* 把带有hidden项都给注释掉
	* 把`grub_cmdline_linux_default`修改为`"text"`
	* `sudo update-grub`
* 重启后发现grub已经更换完毕，将grub设置复原

2. 禁用nouveau驱动
3. 验证系统是否安装了GCC
4. 验证系统是否安装了kernel header和 package development
5. 关闭图形化界面
6. 安装cuda

* `sudo sh cuda.run`

不安装OpenGL，顺便安装NVIDIA显卡驱动。即accept、n、y、y、y

最后显示installed，表示成功了

输入 $ sudo service lightdm start 重新启动图形化界面，没有循环登录则安装成功

* 如果之前安装驱动失败，先卸载

`sudo apt remove --purge nvidia*`

7. 重启电脑，检查Device Node Verification` ls /dev/nvidia*`
8. 设置环境变量
9. 验证驱动版本`cat /proc/driver/nvidia/version`
10. 验证CUDA Toolkit`nvcc -V`
11. 尝试编译cuda提供的例子
如果显示Result = PASS代表成功,若失败 Result = FAIL。这里的提示信息是：`no CUDA-capable device is detected`

**事实是，用上面的方法装了两次都不行，心灰意冷，听从师兄建议，改用在线deb包方式安装，成功**

# 其他问题

* 屏幕分辨率过低且不可调节

```
sudo mv /etc/X11/xorg.conf /etc/X11/xorg.conf.backup
sudo touch /etc/X11/xorg.conf
sudo reboot
```

# 安装CUDNN
[csdn](https://blog.csdn.net/lucifer_zzq/article/details/76675239)
[主要看官方文档](https://developer.nvidia.com/rdp/cudnn-archive)
* 官网下载对应版本cuDNN Library for Linux(cudnn-9.0-linux-x64-v7.tgz)需登录下载
* tar -xzvf cudnn-9.0-linux-x64-v7.tgz
* sudo cp cuda/include/cudnn.h /usr/local/cuda/include
* sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
* sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
* 查看cudnn版本号cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
* 安装成功


# `nvidia-smi`命令
提供监控GPU使用情况和更改GPU状态的功能，是一个跨平台工具，它支持所有标准的NVIDIA驱动程序支持的Linux发行版以及从WindowsServer 2008 R2开始的64位的系统。

`nvidia-smi`命令显示所有GPU的当前状态信息：
* fan：风扇转速
* temp：GPU温度，GPU温度过高会导致GPU频率下降
* perf：性能状态，从P0(最大性能)到P12(最小性能)
* Pwr：GPU功耗
* Persistence-M：持续模式的状态（持续模式耗能大，但在新的GPU应用启动时花费时间更少）
* Bus-Id：GPU总线，domain:bus:device.function
* Disp.A：Display Active，表示GPU的显示是否初始化
* Memory-Usage：显存使用率
* Volatile GPU-Util：GPU使用率
* ECC：是否开启错误检查和纠正技术，0/DISABLED, 1/ENABLED
* Compute M.：计算模式，0/DEFAULT,1/EXCLUSIVE_PROCESS,2/PROHIBITED

* `nvidia-smi -l xxx`动态刷新，不写xxx时默认5s刷新一次
* `nvidia-smi -f xxx`将查询的信息输出到具体的文本中，不在终端显示
* `nvidia-smi -q`查询所有GPU的当前详细信息

手动修改GPU设备选项：
* `nvidia-smi –pm 0/1`,设置持久模式：0/DISABLED,1/ENABLED
* 待补充

[参考](https://blog.csdn.net/handsome_bear/article/details/80903477)

# [vscode中添加cu文件高亮](http://www.makaidong.com/combfish/3694_23320004.html)

* 问题：`*.cu`在VScode不能像`*.cc`或`*.cpp`一样在c++及c++ intelligence插件有关键字的高亮以及go to definition等的操作
* 解决方案：添加*.cu与*.cpp文件的关联

1. VScode： File→Preferences→Setting
2. 在搜索框中输入 “ files.associations”，得到查找结果
3. 在右边的窗口添加  `"files.associations": {"*.cu": "cpp"}`, 保存后即可看到*.cu文件可以像一般的cpp文件操作了

# [CUDA官方入门教程](https://devblogs.nvidia.com/even-easier-introduction-cuda/)

编译并运行C++程序add.`g++ add.cpp -o add.out` `./add.out`

```cpp
#include <iostream>
#include <math.h>
#include <ctime>
#include <cstdio>

// function to add the elements of two arrays
void add(int n, float *x, float *y)
{
  for (int i = 0; i < n; i++)
      y[i] = x[i] + y[i];
}

int main(void)
{
  int N = 1<<20; // 1M elements

  float * x = new float[N];
  float * y = new float[N];

  // initialize x and y arrays on the host
  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  // Run kernel on 1M elements on the CPU
  clock_t start = clock();
  add(N, x, y);
  clock_t finish = clock();
  double duration = (double)(finish - start) / CLOCKS_PER_SEC;
  printf("%f seconds\n",duration);

  // Check for errors (all values should be 3.0f)
  float maxError = 0.0f;
  for (int i = 0; i < N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));
  std::cout << "Max error: " << maxError << std::endl;

  // Free memory
  delete [] x;
  delete [] y;

  return 0;
}
```

C++ 测试时间：0.004925 seconds

修改为CUDA：
1. 将说明符`__global__`添加到函数中，该函数告诉cuda编译器这是一个在GPU上运行并可以在CPU调用的函数。这些  `__global__` 函数称为内核。
2. cuda中的内存分配。在GPU中进行计算需要分配GPU可访问的内存。通过调用`cudaMallocManaged()`获得一个可以供CPU或GPU调用的指针，要释放该指针，只需要将指针传递给`cudaFree()`.因此需要将上面代码中的new和delete分别更换如下：

```cpp
// Allocate Unified Memory -- accessible from CPU or GPU
float *x, *y;
cudaMallocManaged(&x, N*sizeof(float));
cudaMallocManaged(&y, N*sizeof(float));
// Free memory
cudaFree(x);
cudaFree(y);
```

3. 在GPU启动add()，用三角括号语法`<<<>>>`指定CUDA内核启动。`add<<<1, 1>>>(N, x, y);`。需要注意的是，cuda内核并不会阻塞CPU线程，因此CPU要等GPU完成后才能访问结果，需在CPU进行错误检查之前调用`cudaDeviceSynchronize()`

4. 完整代码如下，注意此代码保存为`.cu`格式的cuda文件。

```cpp
#include <iostream>
#include <math.h>
#include <ctime>
#include <cstdio>

// Kernel function to add the elements of two arrays
__global__
void add(int n, float *x, float *y)
{
  for (int i = 0; i < n; i++)
    y[i] = x[i] + y[i];
}

int main(void)
{
  int N = 1<<20;
  float * x, * y;

  // Allocate Unified Memory – accessible from CPU or GPU
  cudaMallocManaged(&x, N*sizeof(float));
  cudaMallocManaged(&y, N*sizeof(float));

  // initialize x and y arrays on the host
  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  // Run kernel on 1M elements on the GPU
  clock_t start = clock();
  add<<<1, 1>>>(N, x, y);
  clock_t finish = clock();
  double duration = (double)(finish - start) / CLOCKS_PER_SEC;
  printf("%f seconds\n",duration);

  // Wait for GPU to finish before accessing on host
  cudaDeviceSynchronize();

  // Check for errors (all values should be 3.0f)
  float maxError = 0.0f;
  for (int i = 0; i < N; i++)
    maxError = fmax(maxError, fabs(y[i]-3.0f));
  std::cout << "Max error: " << maxError << std::endl;

  // Free memory
  cudaFree(x);
  cudaFree(y);

  return 0;
}
```

5. 编译运行`nvcc add.cu -o add_cuda` `./add_cuda`

运行时间：0.000024 seconds

6. 其实，并不需要调用ctime库来查看运行时间，用`nvprof ./add_cuda`命令来显示内核运行时间
7. 现在已经运行了一个内核，其中一个线程可以进行一个计算，但是还没有并行，需要设置`<<<1,1>>>`语法，成为执行配置，显示cuda运行时有多少并行线程用于GPU上的启动。这里有两个参数，第二个参数：线程块中的线程数。CUDA GPU使用大小为32的线程块运行内核，因此256线程是合理的大小
8. 仅做以上修改还是为每个线程执行一个运算，而不是跨并行线程传播计算。要正确运行，我需要修改内核。CUDA C++提供的关键字让内核获得正在运行的线程的索引。具体来说，`threadIdx.x`包含其块内当前线程的索引，`blockDim.x`包含块中的线程数。修改循环以使用并行线程：

```
__global__
void add(int n, float *x, float *y)
{
  int index = threadIdx.x;
  int stride = blockDim.x;
  for (int i = index; i < n; i += stride)
      y[i] = x[i] + y[i];
}
```

9. 再用nvprof来编译，可以看到时间从157ms加快到12ms。
10. CUDA GPU有许多并行处理器，称为streaming Multiprocessors，或SMs。每个SM可以运行多个并发线程块。为了充分利用这些线程，我应该使用多个线程块启动内核。

```
int blockSize = 256;
int numBlocks = (N + blockSize - 1) / blockSize;
add<<<numBlocks, blockSize>>>(N, x, y);
```
![](https://devblogs.nvidia.com/wp-content/uploads/2017/01/cuda_indexing.png)

gridDim.x（线程块数）
blockDim.x（每个块中的线程数）
blockIdx.x（当前块内的索引）
threadIdx.x（块中当前线程的索引）




# CUDA从入门到精通

学习教程[CSDN/卜居](https://blog.csdn.net/kkk584520/article/details/9413973)

cuda编译器nvcc




0
