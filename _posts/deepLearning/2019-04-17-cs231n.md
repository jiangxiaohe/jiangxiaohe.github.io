---
layout: post
title: cs231n课程笔记
tags:
categories: deepLearning
description: 实验笔记
---

[官方笔记](http://cs231n.github.io/)
[官方笔记翻译版](https://zhuanlan.zhihu.com/p/21930884)

# 第一单元：神经网络
## 1 图像分类

从一组固定的类别中为输入图像分配一个标签。很多不同的计算机视觉任务（例如物体检测、分割）可以简化为图像分类。

例如输入是一张图片，共248*400*3个数字组成，总共297,600个数字，输出单个标签"cat"/"dog"。、

面临的挑战在于图像可能发生的变化。比如观察视角变化、观察远近导致的变化、变形、遮挡、照明条件、背景干扰、种群内部差异（比如猫的品种）。

编写图像分类的算法，采用的方法称为 **数据驱动的方法** ，为计算机提供示例图片，然后开发学习算法，查看这些实例，并且了解每个类的视觉表现。

## **第一种方法：最近邻分类器**

与卷积神经网络无关，实践中也很少使用，但是可以让我们了解图像分类的基本方法。实例图像分类数据集：CIFAR-10。CIFAR-10数据集由10个类中的60000个32x32彩色图像组成，每个类有6000个图像。有50000个训练图像和10000个测试图像。 每个图像都标有10个类别中的一个（例如“飞机，汽车，鸟等”）。这些60,000个图像被划分为50,000个图像的训练集和10,000个图像的测试集。

* data_batch_1-5为五个训练集，test_batch为测试集
* 每个batch通过`unpickle`函数得到data和lable变量即可开始训练
* batches.meta包含一个python字典对象，内容有一个包含10个元素的列表

在[官网](http://www.cs.toronto.edu/~kriz/cifar.html)下载并按照说明进行数据预处理如下：

```python

```

现在假设我们获得了50,000张图像的CIFAR-10训练集（每个标签有5,000张图像），我们希望标记剩下的10,000张图像。最近邻分类器将拍摄测试图像，将其与每个训练图像进行比较，并预测最接近的训练图像的标签。可以看到，预测的结果很多是错误的，比如马头的照片被误判为汽车，因为两个照片有相同的黑色背景。

比较两张照片的距离，第一种方法是L1 distance，即用所有像素的绝对值之和来表示两个图像的距离：
$$d_1(I_1,I_1)= \sum_P{(I_1^P-I_2^P)}$$
在python中表示L1距离如下：`distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)`

如果用L1距离实现分类器，对于需要预测的数据，检测出其和所有其他图像的像素差的绝对值的和，找出最小的那张图片，然后用那张图片的归类来预测此图片。可以看到准确率可以达到38.6%。这比随机猜测更令人印象深刻（因为有10个类别可以提供10％的准确度），但是远远没有人类表现（估计大约94％）或接近最先进的卷积神经网络95％，与人类的准确性相匹配。

此外，可以采用L2距离，是计算两个向量之间的欧氏距离的几何解释，距离采取如下形式：
$$d_2= \sqrt{\sum_P{(I_1^P-I_2^P)^2}}$$
在python中diamante如下：`distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))`

在实际的最近邻居应用程序中，我们可以省略平方根操作，因为平方根是单调函数。也就是说，它缩放距离的绝对大小，但它保留了排序，因此最近的邻居有或没有它是相同的。如果您使用此距离在CIFAR-10上运行最近邻分类器，您将获得35.4％的准确度（略低于我们的L1距离结果）。



## **K-最近邻分类器**
我们不是在训练集中找到最近的单个图像，而是找到最前面的k个最近的图像，并让它们在测试图像的标签上投票。特别是，当k = 1时，我们恢复最近邻分类器。直观地说，较高的k值具有平滑效应，使分类器对异常值更具抵抗力，即排除了偏差点的影响：

* 超参数的调整

k近邻分类器需要k的设置。但是哪个数字效果最好？另外，我们看到我们可以使用许多不同的距离函数：L1范数，L2范数，还有许多我们甚至没有考虑的其他选择（例如点积）。这些选择被称为超参数，它们经常出现在许多从数据中学习的机器学习算法的设计中。人们应该选择哪些值/设置通常并不确定。您可能会建议我们尝试使用许多不同的值，看看哪种方法效果最好。这是一个好主意，这确实是我们将要做的，但必须非常谨慎地完成。**特别是，我们不能使用测试集来调整超参数**。无论何时设计机器学习算法，您都应该将测试集视为一种非常宝贵的资源，理想情况下，直到最后一次才能触及。

幸运的是，有一种调整超参数的正确方法，它根本不会触及测试集。我们的想法是将我们的训练集分成两部分：一个稍小的训练集，以及我们称之为验证集的训练集。以CIFAR-10为例，我们可以使用49,000个训练图像进行训练，并留出1,000个进行验证。该验证集主要用作伪测试集来调整超参数。

**将训练集拆分为训练集和验证集。使用验证集调整所有超参数。最后在测试集上运行一次并报告性能。**

**交叉验证**。如果您的训练数据的大小（以及验证数据）可能很小，人们有时会使用更复杂的技术进行超参数调整，称为交叉验证。使用我们之前的示例，我们的想法是，不是任意选择前1000个数据点作为验证集和静态训练集，而是可以获得更好且噪声更小的估计k的某个值。通过迭代不同的验证集并平衡这些验证集的性能来工作。例如，在5倍交叉验证中，我们将训练数据分成5个相等的折叠，其中4个用于训练，1个用于验证。然后我们将迭代哪个折叠是验证折叠，评估性能，最后平均不同折叠的性能。

问题：测试集数据能否代表真实世界中的数据（data out there in the wild）？

KNN的优缺点：
* 实现和理解起来非常简单。
* 分类器没有时间训练，因为所需要的只是存储并可能索引训练数据。但是，我们在测试时支付计算成本，因为对测试示例进行分类需要与每个训练示例进行比较。
* 在某些设置中，最近邻分类器有时可能是一个不错的选择（特别是如果数据是低维的），但它很少适用于实际的图像分类设置。一个问题是图像是高维对象（即它们通常包含许多像素），并且高维空间上的距离可能非常违反直觉。比如，图像偏移、遮挡、变暗都会导致L2距离变大很大。
* 彼此相邻的图像更多地是图像的一般颜色分布，或背景的类型而不是它们的语义标识的函数。例如，可以看到一只狗非常靠近青蛙，因为两者都碰巧在白色背景上。理想情况下，我们希望所有10个类的图像形成自己的聚类，因此相同类的图像彼此相邻，而不管无关的特征和变化（例如背景）。但是，要获得此属性，我们必须超越原始像素。
* 维度灾难。

在实践中运用KNN的步骤：
1. 预处理数据：规范化数据中的要素（例如图像中的一个像素），使其具有零均值和单位方差。我们将在后面的章节中更详细地介绍这一点，并选择不在本节中介绍数据规范化，因为图像中的像素通常是同构的，并且没有表现出大不相同的分布，从而减少了对数据规范化的需求。
2. 如果您的数据非常高维，请考虑使用降维技术，如PCA（维基参考，CS229ref，博客参考）或甚至随机投影。
3. 将训练数据随机分成训练/分组。根据经验，70-90％的数据通常用于训练拆分。此设置取决于您拥有多少超参数以及您希望它们具有多大影响力。如果有很多超参数需要估算，那么你应该在设置更大的验证集以便有效地估算它们时犯错误。如果您担心验证数据的大小，最好将训练数据拆分为折叠并执行交叉验证。如果你能负担得起计算预算，那么使用交叉验证总是更安全（越多越好，但更昂贵）。
4. 针对k的许多选择（例如越多越好）和跨越不同距离类型（L1和L2是好的候选者），在验证数据上训练和评估kNN分类器（对于所有折叠，如果进行交叉验证）
5. 如果您的kNN分类器运行时间过长，请考虑使用近似最近邻库（例如FLANN）来加速检索（以某种精度为代价）。
6. 记下产生最佳结果的超参数。有一个问题是你是否应该使用具有最佳超参数的完整训练集，因为如果你要将验证数据折叠到训练集中，最佳超参数可能会改变（因为数据的大小会更大）。在实践中，不在最终分类器中使用验证数据并且考虑在估计超参数时将其烧毁是更清洁的。评估测试集上的最佳模型。报告测试集准确度，并将结果声明为数据上kNN分类器的性能。



0
