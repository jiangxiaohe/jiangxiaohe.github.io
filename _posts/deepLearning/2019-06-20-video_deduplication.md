---
layout: post
title: 视频去重
tags:
categories: deepLearning
description: 视频如何去重？
---

视频去重：

DNA碱基序列对比，最长公共子序列：O(mn)

# 视频去重概述

[CSDN/jxq0816](https://blog.csdn.net/jxq0816/article/details/79634776)

在以UGC(User Generated Content 用户原创内容)业务为主的视频网站中，每天都有大量的视频被上传。用户上传的视频有数量大、重复视频多的特点，特别是一些热点视频会同时有多个用户上传。这样会导致搜索或者推荐结果中出现大量重复视频。如何识别出这些相同内容的视频，为用户提供更好的搜索和推荐体验，是一个需要解决的问题。

常见的识别相同视频的方法：
* 视频文件md5值去重，只能处理完全相同的视频文件，文件转码或者稍加修改后md5值将变化
* 根据视频的文本信息进行去重（用户在上传视频时会生成标题、描述和标签等文本信息，这些文本信息可以用来描述视频的内容）
  * 建立向量空间模型：根据视频的文本信息，通过分词为视频建立一个文本向量空间模型：[term,weight;.......]。term是根据文本信息提取出的tag，weight是这个tag的权重。使用这个模型代表视频的文本内容，进而近似的表示视频的内容。
  * 计算视频文本信息之间的距离：在为每个视频建立文本向量空间模型后，使计算两个视频之间的差异成为可能，衡量两个文本的距离的模型有很多，简单的余弦距离公式用起来的效果就很不错。通过以上两步可以有效的根据视频文本信息识别出大量的md5值虽然不同但是内容相同的视频，但是这里有个问题就是视频网站的视频库里的视频数量都很大，在数千万甚至上亿的量级上，通过上面的方法进行迭代的效率会很低，不具备工程应用性。
* 根据视频时长进行分类：视频的时间长度是一个重要的参数，不同时间长度的视频可以被认为是内容不同的视频。所以在进行相同视频的去重的算法中可以先根据视频时长对全量视频进行分类，然后根据视频文本信息计算文本距离。通过对全量视频库进行时长统计的结果看，视频的时间长度大部分分布在[1,10000]s的范围内。这样首先可以把上亿的视频根据时间长度分配到大约一万个分类中，每个分类中的视频个数会降到几十万甚至更少。在每个分类中应用视频文本信息距离进行迭代就成为可能。
* 根据图像或者视频内容进行去重：根据文本信息进行去重的劣势是过度依靠文本信息，而视频内容毕竟不能完全用文本来衡量。如果一个视频的文本信息过少的话，去重的结果是不可靠的。所以根本的解决问题的方法是依赖视频内容进行去重。视频本质上是一帧一帧的图像组成的，所以可以把这个问题简化为 **关键帧的图像匹配问题**，著名UGC视频网站Youtube就是采用了这种方法进行视频去重。或者干脆简化一点，根据视频的缩略图进行图像匹配估计也会达到很好的效果。

## 根据内容

去重算法如何评估准确性？

simhash算法实现

还有没有其他的去重算法

# UGC算法
