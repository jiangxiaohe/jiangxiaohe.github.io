---
layout: post
title: 局部敏感哈希LSH
tags:
categories: deepLearning
description: 介绍LSH算法
---

[TOC]

局部敏感哈希（Locality Sensitive Hashing，LSH）算法，又称局部敏感散列算法，顾名思义，该算法产生的散列值是局部敏感的。对原始内容做微小的修改后，经过 LSH算法生成的散列值的变化也是微小的，因此 LSH生成的散列值是局部敏感的。这一特性可以运用在 **论文查重、网页比较、文本比较** 等需要比较内容相似度的场景上。


# 局部敏感哈希在大文本上的应用Simhash

参考[使用SimHash进行海量文本去重](https://www.cnblogs.com/maybe2030/p/5203186.html)

大文本比较采用动态规划方法最长公共子序列LCS算法可以达到更好的效果，但是LCS算法不能较好的使用在大文本的检索和比较上。

SimHash是一种局部敏感hash，它也是Google公司进行海量网页去重使用的主要算法。

simhash是由 Charikar 在2002年提出来的，主要步骤如下：
1. 分词。把需要判断文本分词形成这个文章的特征单词。最后形成去掉噪音词的单词序列并为每个词加上权重，我们假设权重分为5个级别（1~5）。比如：“ 美国“51区”雇员称内部有9架飞碟，曾看见灰色外星人 ” ==> 分词后为 “ 美国（4） 51区（5） 雇员（3） 称（1） 内部（2） 有（1） 9架（3） 飞碟（5） 曾（1） 看见（3） 灰色（4） 外星人（5）”，括号里是代表单词在整个句子里重要程度，数字越大越重要。
2. hash，通过hash算法把每个词变成hash值，比如“美国”通过hash算法计算为 100101,“51区”通过hash算法计算为 101011。
3. 加权，通过 2步骤的hash生成结果，需要按照单词的权重形成加权数字串，比如“美国”的hash值为“100101”，通过加权计算为“4 -4 -4 4 -4 4”；“51区”的hash值为“101011”，通过加权计算为 “ 5 -5 5 -5 5 5”。
4. 合并，把上面各个单词算出来的序列值累加，变成只有一个序列串。比如 “美国”的 “4 -4 -4 4 -4 4”，“51区”的 “ 5 -5 5 -5 5 5”， 把每一位进行累加， “4+5 -4+-5 -4+5 4+-5 -4+5 4+5” ==》 “9 -9 1 -1 1 9”。这里作为示例只算了两个单词的，真实计算需要把所有单词的序列串累加。
5. 降维，把4步算出来的 “9 -9 1 -1 1 9” 变成 0 1 串，形成我们最终的simhash签名。 如果每一位大于0 记为 1，小于0 记为 0。最后算出结果为：“1 0 1 0 1 1”。
6. 将每个文本都转化为simhash签名，并转化为long型存储，空间大大减小。然后用汉明距离比较相似度。
7. simhash的存储和索引和传统的词典不同，因此采用分块存储和查找的方法。

查找和存储方法：

**把 64 位的二进制simhash签名均分成4块，每块16位。根据抽屉原理，如果两个签名的海明距离在 3 以内，它们必有一块完全相同。**
然后把分成的4块中的每一个块分别作为索引来进行查找，即先hash再链表。

![](https://images2015.cnblogs.com/blog/764050/201602/764050-20160220134028128-1522804689.png)

注意：
* 当文本内容较长时，使用SimHash准确率很高，SimHash处理短文本内容准确率往往不能得到保证；
* 文本内容中每个term对应的权重如何确定要根据实际的项目需求，一般是可以使用IDF权重来进行计算。

示例程序
[github/leonsim/simhash](https://github.com/leonsim/simhash)

安装`pip install simhash`

```python
import re
from simhash import Simhash, SimhashIndex
def get_features(s):
    width = 3
    s = s.lower()
    s = re.sub(r'[^\w]+', '', s)
    return [s[i:i + width] for i in range(max(len(s) - width + 1, 1))]

data = {
    1: u'How are you? I Am fine. blar blar blar blar blar Thanks.',
    2: u'How are you i am fine. blar blar blar blar blar than',
    3: u'This is simhash test.',
}
objs = [(str(k), Simhash(get_features(v))) for k, v in data.items()]
index = SimhashIndex(objs, k=3)

print(type(index)) # <class 'simhash.SimhashIndex'>

print index.bucket_size()

s1 = Simhash(get_features(u'How are you i am fine. blar blar blar blar blar thank'))
print index.get_near_dups(s1)

index.add('4', s1)
print index.get_near_dups(s1)

print Simhash('aa').distance(Simhash('bb'))
print Simhash('aa').distance(Simhash('aa'))
```

# 局部敏感哈希(Locality-Sensitive Hashing, LSH)

[CSDN/君的名字](https://blog.csdn.net/chichoxian/article/details/80290782)

许多的数据挖掘问题都可以表示为发现相似的集合的问题：
* 网页有很多的相似的词汇，可以用来根据主题来分类
* 电影的推荐系统
* 根据某个电影找到喜欢同类电影的人

相似的文档例子
* 镜像网站（mirror sites）
* 剽窃问题 包括大量的引用
* 相似的新闻在很多的不同的网站

## 基本概念和整体架构

* shingling:可以理解为对一个文档进行切割
* minhashing:将一个大的集合中的元素转换为很多短小的签名，但是保持了这些集合中的元素的相似性。
* Locality-sensitive hashing: 关注的是签名对可能的相似性

1. 首先接收到文档，然后shingling，将文档切割成一个一个的元素，这些元素是由k个字符串组成
2. 用Minhashing 得到我们集合元素的签名
3. 产生可能的候选对


k-shingles与minhash技术https://blog.csdn.net/aspirinvagrant/article/details/41281101

K-shingle，又叫做是k-gram 。一个文档可以看成是K个字符组成的一个集合。

Jaccard similarity 指的就是两个集合交集的个数除以两个几何并集的个数。

minhash 函数 h(c) = 表示的是在某一列中的第一个出现1的那一行的行号,我们用这个行号中第一次出现1的那个行来做我们这个矩阵的那一列的特征值。




[cnblogs/火星十一郎](https://www.cnblogs.com/hxsyl/p/4627477.html)









# 乘积量化PQ(product quantization) 算法

https://blog.csdn.net/mydear_11000/article/details/83749059

意思是指把原来的向量空间分解为若干个低维向量空间的笛卡尔积，并对分解得到的低维向量空间分别做量化（quantization）。这样每个向量就能由多个低维空间的量化code组合表示。

该方法用于解决相似搜索问题、或者说近邻搜索问题。PQ方法是高效相似搜索方法的一种。

在介绍PQ算法前，先简要介绍vector quantization
https://blog.csdn.net/lishuiwang/article/details/78483547


ResNet介绍https://blog.csdn.net/u013181595/article/details/80990930

openCV如何在cuda中运用

CUDA Samples给入门想看代码又不知道看点啥的小同学提供一些指引
https://blog.csdn.net/fishseeker/article/details/76708830
