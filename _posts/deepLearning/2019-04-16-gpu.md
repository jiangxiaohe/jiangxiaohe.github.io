---
layout: post
title: GPU编程与配置
tags:
categories: deepLearning
description: 实验笔记
---

# `nvidia-smi`命令
提供监控GPU使用情况和更改GPU状态的功能，是一个跨平台工具，它支持所有标准的NVIDIA驱动程序支持的Linux发行版以及从WindowsServer 2008 R2开始的64位的系统。

`nvidia-smi`命令显示所有GPU的当前状态信息：
* fan：风扇转速
* temp：GPU温度，GPU温度过高会导致GPU频率下降
* perf：性能状态，从P0(最大性能)到P12(最小性能)
* Pwr：GPU功耗
* Persistence-M：持续模式的状态（持续模式耗能大，但在新的GPU应用启动时花费时间更少）
* Bus-Id：GPU总线，domain:bus:device.function
* Disp.A：Display Active，表示GPU的显示是否初始化
* Memory-Usage：显存使用率
* Volatile GPU-Util：GPU使用率
* ECC：是否开启错误检查和纠正技术，0/DISABLED, 1/ENABLED
* Compute M.：计算模式，0/DEFAULT,1/EXCLUSIVE_PROCESS,2/PROHIBITED

* `nvidia-smi -l xxx`动态刷新，不写xxx时默认5s刷新一次
* `nvidia-smi -f xxx`将查询的信息输出到具体的文本中，不在终端显示
* `nvidia-smi -q`查询所有GPU的当前详细信息

手动修改GPU设备选项：
* `nvidia-smi –pm 0/1`,设置持久模式：0/DISABLED,1/ENABLED
* 待补充

[参考](https://blog.csdn.net/handsome_bear/article/details/80903477)







0
