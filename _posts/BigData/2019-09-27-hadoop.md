---
layout: post
title: Hadoop实验
tags:
categories: BigData
description:
---

环境：搭建Docker伪分布式集群环境

# 在ubuntu搭建Docker环境

参考[CSDN教程](https://blog.csdn.net/yx_222/article/details/80936757)

[官方安装教程](https://docs.docker.com/install/linux/docker-ce/ubuntu/#set-up-the-repository)

```
//为了使apt可以通过https使用Repository，先安装以下包
sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common
//添加Docker官方GPG密钥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
//检查GPG Key信息是否正确
sudo apt-key fingerprint 0EBFCD88
//将源信息直接写入/etc/apt/sources.list
sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
//再更新下apt包索引
sudo apt-get update
//确认Docker的源信息是否正确, 新的源是否添加成功
sudo apt-cache madison docker-ce
//安装最新版本的Docker CE
sudo apt-get install -y docker-ce
//Docker安装验证
sudo docker -v
sudo docker version

//启动docker
sudo systemctl start docke
//运行Hello World，校验Docker是否安装成功
sudo docker run hello-world
```

docker常用命令
* docker images列出所有镜像
* docker ps列出正在运行的容器，-a :显示所有的容器，包括未运行的
* docker pull docker-spark-hadoop 下载镜像
* docker run -i -t ubuntu /bin/bash
  * -i: 以交互模式运行容器，通常与 -t 同时使用
  * -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用；
  * -h "mars": 指定容器的hostname
  * --name="nginx-lb": 为容器指定一个名称
* docker commit 在本地仓库提交更改(类似git)
* docker rm contrainer-id 删除容器
* docker attach container 连接正在运行的容器
* docker start container 启动一个或多个已经被停止的容器

# docker环境下搭建hadoop集群(ubuntu16.04 LTS系统）

## 下载hadoop镜像并且配置ssh互联

[参考CSDN](https://blog.csdn.net/wangzi11111111/article/details/88890988)

* 从阿里云库拉取hadoop镜像，下载镜像registry.cn-beijing.aliyuncs.com/bitnp/docker-spark-hadoop，这个镜像把我们需要的工具基本下好了，比如 jdk、hadoop、spark。
`docker pull registry.cn-beijing.aliyuncs.com/bitnp/docker-spark-hadoop`

* 使用指令`docker images`查看是否下载成功

* 在这个docker镜像中创建是三个容器(Master Slave1 Slave2)
* 创建matser容器：`docker run -it --name Master -h Master registry.cn-beijing.aliyuncs.com/bitnp/docker-spark-hadoop /bin/bash`
* 此时，就把Master容器创建出来了，按键`ctrl+P+Q`会返回主机的命令行，但是并不会退出Master容器，如果用`ctrl+c`则会退出Master容器。
* 同样，继续创建slave1和slave2容器。
`docker run -it --name Slave1 -h Slave1 registry.cn-beijing.aliyuncs.com/bitnp/docker-spark-hadoop /bin/bash`
* 至此，三个容器已经创建完毕，接下来需要通过ssh将三个容器连接起来。

* 首先对Master进行配置，进入Master容器`docker attach Master`
* docker里面没有指令apt-get，没有指令gedit，但是里面有yum，可以用yum下载vim来编辑文件，还可以用yum下载openssh-clients，openssh-server.如果你在docker里面连yum都没有，那么你先使用Ctrl+P+Q退出，在初始目录用apt-get下载一个yum(指令是  sudo apt-get  install yum )，然后在docker里面就可以使用了。
* `yum -y install vim` `yum -y install openssh-clients` `yum -y install openssh-server`
* 配置Master容器的ssh秘钥
  * `/usr/sbin/sshd`
  * `/usr/sbin/sshd-keygen -A`
  * `/usr/sbin/sshd`
  * 三步不可少，不然会出问题
* 制作秘钥`ssh-keygen -t rsa`，默认生成`/root/.ssh/id_rsa.pub`
* 我们需要把密钥存储在 /root/.ssh/authorized_keys 文件中，指令是： `cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys`
* 为了使得ssh连接时更加简洁，需要配置两个文件
```cpp
vim /etc/ssh/sshd_config
'''
Port 22
PermitRootLogin yes
PubkeyAuthentication yes
PasswordAuthentication yes
ChallengeResponseAuthentication no
UsePAM yes
PrintLastLog no
'''
vim /etc/ssh/ssh_config
'''
StrictHostKeyChecking no
'''
```

* 新开一个命令行界面，看下三个容器的ip地址`sudo docker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(sudo docker ps -aq) `可以看到ip地址分别为
`/Master - 172.17.0.2
/Slave1 - 172.17.0.3
/Slave2 - 172.17.0.4`

* 在Master容器中，打开 /etc/hosts 文件，把上述内容填上，目的是给每个节点的 ip 附上名字，ssh连接的时候就可以直接  ssh Slave1，而不是 ssh 172.17.0.3 这么麻烦了。` vim /etc/hosts`
```
172.17.0.2      Master
172.17.0.3      Slave1
172.17.0.4      Slave2
```
* 最后一步，将秘钥文件存入另外两个机器的文件当中，直接复制即可。`vim /root/.ssh/authorized_keys`

## 配置环境变量
* 首先查看JAVE_HOME的地址`echo $JAVA_HOME`
* 接下来一次配置每个容器的 core-site.xml 和 yarn-site.xml 和 mapred-site.xml 及 hdfs-site.xml 文件
* 首先使用 find / -name core-site.xml 的具体路径，然后用指令  vim + 文件路径  进入这个文件.`vim /usr/local/hadoop-2.7.5/etc/hadoop/core-site.xml`

```
<!-- Put site-specific property overrides in this file. -->
<configuration>
      <property>
          <name>fs.defaultFS</name>
          <value>hdfs://Master:9000</value>
      </property>
      <property>
         <name>io.file.buffer.size</name>
         <value>131072</value>
     </property>
     <property>
          <name>hadoop.tmp.dir</name>
          <value>/usr/local/hadoop-2.7.5/tmp</value>
     </property>
</configuration>
```

* 进入yarn-site.xml 进行配置，结束后保存退出。`vim /usr/local/hadoop-2.7.5/etc/hadoop/yarn-site.xml`

```
limitations under the License. See accompanying LICENSE file.
-->
<configuration>
     <property>
         <name>yarn.nodemanager.aux-services</name>
         <value>mapreduce_shuffle</value>
     </property>
     <property>
         <name>yarn.resourcemanager.address</name>
         <value>Master:8032</value>
     </property>
     <property>
         <name>yarn.resourcemanager.scheduler.address</name>
         <value>Master:8030</value>
     </property>
     <property>
         <name>yarn.resourcemanager.resource-tracker.address</name>
         <value>Master:8031</value>
     </property>
     <property>
         <name>yarn.resourcemanager.admin.address</name>
         <value>Master:8033</value>
     </property>
     <property>
         <name>yarn.resourcemanager.webapp.address</name>
         <value>Master:8088</value>
     </property>
     <property>
         <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
         <value>org.apache.hadoop.mapred.ShuffleHandler</value>
     </property>
</configuration>
```

* 进入mapred-site.xml  进行配置，结束后保存退出。`vim /usr/local/hadoop-2.7.5/etc/hadoop/mapred-site.xml`

```
<!-- Put site-specific property overrides in this file. -->
<configuration>
 <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

* 进入hdfs-site.xml  进行配置，结束后保存退出。`vim /usr/local/hadoop-2.7.5/etc/hadoop/hdfs-site.xml`

```
<!-- Put site-specific property overrides in this file. -->
<configuration>
    <property>
      <name>dfs.replication</name>
      <value>2</value>
    </property>
    <property>
      <name>dfs.namenode.name.dir</name>
      <value>file:/usr/local/hadoop-2.7.5/hdfs/name</value>
    </property>
</configuration>
```

* 在步骤I 中是配置 Master 容器的环境变量，我们还需要进入Slave1容器，相同的代码把 Slave1的环境变量也配置完，当然容器slave2也是如此。唯一不同的是在步骤⑤ 的hdfs-site.xml中，Master容器设置的是namenode，而Slave1和Slave2设置的是datanode，如下:

```
<!-- Put site-specific property overrides in this file. -->
<configuration>
    <property>
      <name>dfs.replication</name>
      <value>2</value>
    </property>
    <property>
      <name>dfs.datanode.data.dir</name>
      <value>file:/usr/local/hadoop-2.7.5/hdfs/data</value>
    </property>
</configuration>
```

* 删除三个容器的hdfs目录`rm -rf /usr/local/hadoop-2.7.5/hdfs`
* 在Master下简历name文件夹`mkdir -p /usr/local/hadoop-2.7.5/hdfs/name`
* 在Slave下简历data文件夹`mkdir -p /usr/local/hadoop-2.7.5/hdfs/data`

* 格式化NameNode HDFS目录，在Master容器中，使用指令 hdfs namenode -format
* 进入sbin文件，来启动hadoop集群。`cd /usr/local/hadoop-2.7.5/sbin`
* 然后我们使用指令 `./start-all.sh`  来启动集群
* 使用 jps 查看 namenode 是否启动，此时看的是Master容器的namenode是否启动。
* 这里我们可以使用  ssh Slave1  (或ssh Slave2)进入Slave1容器，然后使用指令  jps  查看datanode是否启动，此时会出现`-bash: jps: command not found` 错误，需要配置` /etc/profile`文件，三个容器都要配置。在末尾添加，添加后执行`source /etc/profile`

```
export JAVA_HOME=/usr/local/jdk1.8.0_162
export HADOOP_HOME=/usr/local/hadoop-2.7.5
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

* 可以使用指令 hadoop dfsadmin -report   查看其他容器有没有启动

问题：并没与出现预想的结果，可能的问题是：对于配置文件的不理解，可能导致错误，并没有出现集群协作的配置部分。
